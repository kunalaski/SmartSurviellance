{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from motrackers.detectors import YOLOv3\n",
    "from motrackers import CentroidTracker, CentroidKF_Tracker, SORT, IOUTracker\n",
    "#from motrackers.utils import draw_tracks\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE = \"test.mp4\"\n",
    "WEIGHTS_PATH = './examples/pretrained_models/yolo_weights/yolov4.weights'\n",
    "CONFIG_FILE_PATH = './examples/pretrained_models/yolo_weights/yolov4.cfg'\n",
    "LABELS_PATH = \"./examples/pretrained_models/yolo_weights/coco_names.json\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "MAX_SEQ_LENGTH = 2000\n",
    "NUM_FEATURES = 2048\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.2\n",
    "DRAW_BOUNDING_BOXES = True\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracker = CentroidKF_Tracker(max_lost=0, tracker_output_format='mot_challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv3(\n",
    "    weights_path=WEIGHTS_PATH,\n",
    "    configfile_path=CONFIG_FILE_PATH,\n",
    "    labels_path=LABELS_PATH,\n",
    "    confidence_threshold=CONFIDENCE_THRESHOLD,\n",
    "    nms_threshold=NMS_THRESHOLD,\n",
    "    draw_bboxes=DRAW_BOUNDING_BOXES,\n",
    "    use_gpu=USE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocrop(image, threshold=0):\n",
    "    \"\"\"Crops any edges below or equal to threshold\n",
    "\n",
    "    Crops blank image to 1x1.\n",
    "\n",
    "    Returns cropped image.\n",
    "\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        flatImage = np.max(image, 2)\n",
    "    else:\n",
    "        flatImage = image\n",
    "    assert len(flatImage.shape) == 2\n",
    "\n",
    "    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n",
    "    if rows.size:\n",
    "        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n",
    "        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n",
    "    else:\n",
    "        image = image[:1, :1]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[145, 138, 144],\n",
       "         [158, 151, 157],\n",
       "         [158, 157, 154],\n",
       "         ...,\n",
       "         [151, 154, 154],\n",
       "         [141, 148, 145],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[153, 148, 156],\n",
       "         [174, 167, 175],\n",
       "         [162, 156, 166],\n",
       "         ...,\n",
       "         [144, 147, 147],\n",
       "         [143, 150, 147],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 155],\n",
       "         [140, 145, 159],\n",
       "         [148, 157, 172],\n",
       "         ...,\n",
       "         [131, 132, 135],\n",
       "         [147, 155, 154],\n",
       "         [219, 227, 226]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98, 108, 125],\n",
       "         [103, 111, 128],\n",
       "         [102, 112, 129],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 53,  48,  48]],\n",
       "\n",
       "        [[101, 112, 127],\n",
       "         [101, 110, 125],\n",
       "         [102, 107, 125],\n",
       "         ...,\n",
       "         [ 63,  55,  57],\n",
       "         [ 55,  53,  49],\n",
       "         [ 51,  49,  45]],\n",
       "\n",
       "        [[ 99, 110, 125],\n",
       "         [101, 111, 126],\n",
       "         [103, 108, 126],\n",
       "         ...,\n",
       "         [ 63,  54,  57],\n",
       "         [ 55,  54,  48],\n",
       "         [ 48,  47,  41]]],\n",
       "\n",
       "\n",
       "       [[[145, 138, 144],\n",
       "         [158, 151, 157],\n",
       "         [158, 157, 154],\n",
       "         ...,\n",
       "         [151, 154, 154],\n",
       "         [141, 148, 145],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[153, 148, 156],\n",
       "         [174, 167, 175],\n",
       "         [162, 156, 166],\n",
       "         ...,\n",
       "         [144, 147, 147],\n",
       "         [143, 150, 147],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 155],\n",
       "         [140, 145, 159],\n",
       "         [149, 157, 173],\n",
       "         ...,\n",
       "         [131, 132, 135],\n",
       "         [147, 155, 154],\n",
       "         [219, 227, 226]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98, 108, 125],\n",
       "         [103, 111, 128],\n",
       "         [102, 112, 129],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 53,  48,  48]],\n",
       "\n",
       "        [[103, 111, 128],\n",
       "         [103, 108, 126],\n",
       "         [102, 107, 125],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 55,  54,  48],\n",
       "         [ 51,  50,  43]],\n",
       "\n",
       "        [[101, 109, 126],\n",
       "         [104, 109, 127],\n",
       "         [103, 108, 126],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 55,  55,  46],\n",
       "         [ 48,  48,  39]]],\n",
       "\n",
       "\n",
       "       [[[145, 138, 144],\n",
       "         [158, 151, 157],\n",
       "         [158, 157, 154],\n",
       "         ...,\n",
       "         [151, 154, 154],\n",
       "         [141, 148, 145],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[153, 148, 156],\n",
       "         [174, 167, 175],\n",
       "         [162, 156, 166],\n",
       "         ...,\n",
       "         [144, 147, 147],\n",
       "         [143, 150, 147],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 155],\n",
       "         [140, 145, 159],\n",
       "         [149, 157, 173],\n",
       "         ...,\n",
       "         [131, 132, 135],\n",
       "         [147, 155, 154],\n",
       "         [219, 227, 226]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 98, 108, 125],\n",
       "         [103, 111, 128],\n",
       "         [102, 112, 129],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 53,  48,  48]],\n",
       "\n",
       "        [[103, 111, 128],\n",
       "         [103, 108, 126],\n",
       "         [102, 107, 125],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 55,  54,  48],\n",
       "         [ 51,  50,  43]],\n",
       "\n",
       "        [[101, 109, 126],\n",
       "         [104, 109, 127],\n",
       "         [103, 108, 126],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 55,  55,  46],\n",
       "         [ 48,  48,  39]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[147, 139, 145],\n",
       "         [159, 152, 158],\n",
       "         [159, 157, 155],\n",
       "         ...,\n",
       "         [152, 156, 156],\n",
       "         [140, 148, 145],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[151, 145, 153],\n",
       "         [175, 169, 176],\n",
       "         [157, 152, 162],\n",
       "         ...,\n",
       "         [146, 149, 149],\n",
       "         [141, 149, 147],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 156],\n",
       "         [142, 146, 160],\n",
       "         [149, 158, 174],\n",
       "         ...,\n",
       "         [135, 136, 139],\n",
       "         [147, 154, 154],\n",
       "         [220, 228, 227]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[107, 114, 135],\n",
       "         [ 94,  96, 127],\n",
       "         [ 69,  70,  98],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 55,  51,  47]],\n",
       "\n",
       "        [[ 67,  75,  81],\n",
       "         [ 43,  47,  56],\n",
       "         [ 41,  44,  62],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 58,  54,  50],\n",
       "         [ 56,  54,  47]],\n",
       "\n",
       "        [[188, 118,  95],\n",
       "         [188, 118,  95],\n",
       "         [188, 118,  95],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 56,  54,  50],\n",
       "         [ 52,  53,  45]]],\n",
       "\n",
       "\n",
       "       [[[147, 139, 145],\n",
       "         [159, 152, 158],\n",
       "         [159, 157, 155],\n",
       "         ...,\n",
       "         [152, 156, 156],\n",
       "         [140, 148, 145],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[151, 145, 153],\n",
       "         [175, 169, 176],\n",
       "         [157, 152, 162],\n",
       "         ...,\n",
       "         [144, 147, 147],\n",
       "         [141, 149, 147],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 156],\n",
       "         [142, 146, 160],\n",
       "         [149, 158, 174],\n",
       "         ...,\n",
       "         [135, 136, 139],\n",
       "         [147, 154, 154],\n",
       "         [220, 228, 227]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 92,  97, 136],\n",
       "         [ 74,  78, 105],\n",
       "         [ 44,  43,  64],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 55,  51,  47]],\n",
       "\n",
       "        [[ 84,  84, 116],\n",
       "         [ 65,  65,  93],\n",
       "         [ 65,  68,  86],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 58,  54,  50],\n",
       "         [ 56,  54,  47]],\n",
       "\n",
       "        [[ 99,  74,  72],\n",
       "         [102,  76,  80],\n",
       "         [ 91,  68,  69],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 56,  54,  50],\n",
       "         [ 52,  53,  45]]],\n",
       "\n",
       "\n",
       "       [[[147, 139, 145],\n",
       "         [159, 152, 158],\n",
       "         [159, 157, 155],\n",
       "         ...,\n",
       "         [152, 156, 156],\n",
       "         [138, 146, 143],\n",
       "         [220, 228, 225]],\n",
       "\n",
       "        [[151, 145, 153],\n",
       "         [175, 169, 176],\n",
       "         [159, 153, 163],\n",
       "         ...,\n",
       "         [144, 147, 147],\n",
       "         [141, 149, 146],\n",
       "         [217, 225, 222]],\n",
       "\n",
       "        [[137, 142, 156],\n",
       "         [142, 146, 160],\n",
       "         [148, 158, 173],\n",
       "         ...,\n",
       "         [135, 137, 139],\n",
       "         [147, 155, 154],\n",
       "         [220, 228, 227]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 65,  68,  90],\n",
       "         [ 49,  45,  62],\n",
       "         [ 63,  57,  75],\n",
       "         ...,\n",
       "         [ 61,  55,  59],\n",
       "         [ 57,  52,  51],\n",
       "         [ 55,  51,  47]],\n",
       "\n",
       "        [[ 71,  71,  99],\n",
       "         [ 44,  42,  64],\n",
       "         [ 51,  50,  64],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 56,  53,  49],\n",
       "         [ 54,  52,  46]],\n",
       "\n",
       "        [[ 63,  63,  91],\n",
       "         [ 74,  74,  96],\n",
       "         [ 43,  54,  67],\n",
       "         ...,\n",
       "         [ 61,  56,  56],\n",
       "         [ 58,  54,  50],\n",
       "         [ 55,  53,  47]]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def main(video_path, model, tracker):\n",
    "    frames = []\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    colorTracker = {}\n",
    "    trk_dict={}\n",
    "    count = 0\n",
    "    prev_frame_time = 0\n",
    "    new_frame_time = 0\n",
    "    try:\n",
    "        while True:\n",
    "            ok, image = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "            \n",
    "            image = cv.resize(image, (700, 500))\n",
    "            booli, output = model.detect(image)\n",
    "            #print('below detect')\n",
    "            if(booli != False):\n",
    "                bboxes, confidences, class_ids = output\n",
    "                tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "                #print(class_ids)\n",
    "                #print('below tracking')\n",
    "                image, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "                #print('below drawing')\n",
    "                \n",
    "                #frame = crop_center_square(updated_image)\n",
    "#             gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "#             _,thresh = cv.threshold(gray,1,255,cv.THRESH_BINARY)\n",
    "#             contours,hierarchy = cv.findContours(thresh,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "#             cnt = contours[0]\n",
    "#             x,y,w,h = cv.boundingRect(cnt)\n",
    "#             frame = image[y:y+h,x:x+w]\n",
    "            #print(image.shape)\n",
    "            image = autocrop(image)\n",
    "            frame = cv.resize(image, (224, 224))\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "            #print('below resize')\n",
    "           # frame = frame[20:210, 10:210]\n",
    "            frames.append(frame)\n",
    "            #print('below append')\n",
    "            count += 1\n",
    "            #print(count)\n",
    "            #print(type(frames))\n",
    "            #print(f'{count}-{fps}')\n",
    "            cv.imshow(\"image\", frame)\n",
    "            #print('below show')\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    return np.array(frames)\n",
    "main('test.mp4', model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dir(path):\n",
    "#     try:\n",
    "#         os.stat(path)\n",
    "#     except:\n",
    "#         os.mkdir(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_dirs():\n",
    "#     create_dir('E:/dataset/')\n",
    "#     create_dir('E:/dataset/Train/')\n",
    "#     create_dir('E:/dataset/Test')\n",
    "#     create_dir('E:/dataset/Train/Anomaly/')\n",
    "#     create_dir('E:/dataset/Test/Anomaly/')\n",
    "#     create_dir('E:/dataset/Train/Normal/')\n",
    "#     create_dir('E:/dataset/Test/Normal/')\n",
    "# initialize_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(start_path = 'data/'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainAno = pd.read_csv(\"AnomalyTrain.csv\")\n",
    "for i in trainAno.index:\n",
    "    if trainAno.at[i, 'progress'] == -1:\n",
    "        vid = trainAno.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Train/Anomaly/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        trainAno.at[i, 'progress'] = 1\n",
    "        trainAno.at[i, 'count'] = count\n",
    "        trainAno.to_csv('AnomalyTrain.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAno = pd.read_csv(\"AnomalyTest.csv\")\n",
    "for i in testAno.index:\n",
    "    if testAno.at[i, 'progress'] == -1:\n",
    "        vid = testAno.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Test/Anomaly/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        testAno.at[i, 'progress'] = 1\n",
    "        testAno.at[i, 'count'] = count\n",
    "        testAno.to_csv('AnomalyTest.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNor = pd.read_csv(\"NormalTrain.csv\")\n",
    "for i in testNor.index:\n",
    "    if testNor.at[i, 'progress'] == -1:\n",
    "        vid = testNor.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Test/Normal/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        testNor.at[i, 'progress'] = 1\n",
    "        testNor.at[i, 'count'] = count\n",
    "        testNor.to_csv('NormalTrain.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNor = pd.read_csv(\"NormalTest.csv\")\n",
    "print(trainNor.index)\n",
    "for i in trainNor.index:\n",
    "    if trainNor.at[i, 'progress'] == -1:\n",
    "        vid = trainNor.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Train/Normal/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        trainNor.at[i, 'progress'] = 1\n",
    "        trainNor.at[i, 'count'] = count\n",
    "        trainNor.to_csv('NormalTest.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "frames = []\n",
    "colorTracker = {}\n",
    "image = cv.imread(\"street2.jpg\")\n",
    "image = cv.resize(image, (700, 500))\n",
    "booli, output = model.detect(image)\n",
    "if(booli == False):\n",
    "    frame = cv.resize(output, (224, 224))\n",
    "    #print(f'false:{count}')\n",
    "else:\n",
    "    bboxes, confidences, class_ids = output\n",
    "    tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "    #print(class_ids)\n",
    "#             print(len(tracks))\n",
    "    frame, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    plt.imshow(frame)\n",
    "# frame = frame[20:210, 10:210]\n",
    "#print(count)\n",
    "#print(type(frames))\n",
    "#print(f'{count}-{fps}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('obj2.jpg', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "AWS_ACCESS_KEY_ID  = os.environ.get('s3_access_key')\n",
    "AWS_SECRET_ACCESS_KEY  = os.environ.get('s3_secret_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "\n",
    "def upload_to_aws(local_file, bucket, s3_file):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                      aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import re\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)',text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_path = 'E:/Dataset/Test/Anomaly'\n",
    "file_list=os.listdir(class_path) # create list of files in class directory\n",
    "file_list.sort(key=natural_keys)\n",
    "for f in file_list:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "class_path = 'E:/Dataset/Test/Anomaly'\n",
    "file_list=os.listdir(class_path) # create list of files in class directory\n",
    "count = 0\n",
    "testAnomalyImage=[]\n",
    "file_list.sort(key=natural_keys)\n",
    "for f in tqdm(file_list):\n",
    "    fpath=os.path.join (class_path,f)\n",
    "    img = cv2.imread(fpath, 0)\n",
    "    testAnomalyImage.append(np.array(img, dtype=np.uint8))\n",
    "\n",
    "print('Start Dumping')\n",
    "    \n",
    "with open(\"testAnomaly\", \"wb\") as f:\n",
    "    pickle.dump(testAnomalyImage, f)\n",
    "del testAnomalyImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class_path = 'E:/Dataset/Test/Normal'\n",
    "file_list=os.listdir(class_path) # create list of files in class directory\n",
    "count = 0\n",
    "testNormalImage=[]\n",
    "file_list.sort(key=natural_keys)\n",
    "for f in tqdm(file_list):\n",
    "    fpath=os.path.join (class_path,f)\n",
    "    img = cv2.imread(fpath, 0)\n",
    "    testNormalImage.append(np.array(img, dtype=np.uint8))\n",
    "    \n",
    "print('Start Dumping')\n",
    "\n",
    "hf = h5py.File('TestDataset.h5', 'w')\n",
    "\n",
    "%%time\n",
    "hf.create_dataset('trainNormal', data=testNormalImage)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hf.create_dataset('trainNormal', data=testNormalImage)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testNormalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class_path = 'E:/Dataset/Train/Anomaly'\n",
    "file_list=os.listdir(class_path) # create list of files in class directory\n",
    "count = 0\n",
    "deleteRob=[]\n",
    "for f in file_list:\n",
    "    if \"Robbery\" in str(f) or \"Shoplifting\" in str(f) or \"Stealing\" in str(f):\n",
    "        print(f)\n",
    "        deleteRob.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in tqdm(deleteRob):\n",
    "    os.remove(\"E:/Dataset/Train/Anomaly/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deleteRob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hf.create_dataset('trainAnomaly', data=trainAnomalyImage)\n",
    "\n",
    "del trainAnomalyImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class_path = 'E:/Dataset/Train/Normal'\n",
    "file_list=os.listdir(class_path) # create list of files in class directory\n",
    "count = 0\n",
    "trainNormalImage=[]\n",
    "file_list.sort(key=natural_keys)\n",
    "for f in tqdm(file_list):\n",
    "    fpath=os.path.join (class_path,f)\n",
    "    img = cv2.imread(fpath, 0)\n",
    "    trainNormalImage.append(np.array(img, dtype=np.uint8))\n",
    "     \n",
    "hf = h5py.File('TrainDatasetNormal.h5', 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hf.create_dataset('trainNormal', data=trainNormalImage)\n",
    "print('Delete')\n",
    "del trainNormalImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "objects = []\n",
    "with (open(\"testAnomaly\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "hf = h5py.File('TestAnomaly.h5', 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hf.create_dataset('testAnomaly', data=objects[0])\n",
    "print('Delete')\n",
    "del objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                                                                        \n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices()) # list of DeviceAttributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (224,224)\n",
    "NEGATIVES_PATH_TRAIN = 'E:/dataset/Train/Normal/'\n",
    "POSITIVES_PATH_TRAIN = 'E:/dataset/Train/Anomaly/'\n",
    "POSITIVES_PATH_VALID = 'E:/dataset/Test/Normal/'\n",
    "NEGATIVES_PATH_VALID = 'E:/dataset/Test/Anomaly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_conv.summary()\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(vgg_conv, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add the vgg convolutional base model\n",
    "    model.add(vgg_conv)\n",
    "\n",
    "    # Add new layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "build_feature_extractor().summary()\n",
    "tf.keras.utils.plot_model(build_feature_extractor(), to_file='model2.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_batchsize = 16\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory('E:/dataset/Train/', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "val_generator = val_datagen.flow_from_directory('E:/dataset/Test/', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "validation_steps_per_epoch = 1000\n",
    "predictions = model2.predict_generator(val_generator, steps=validation_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E:\\Dataset\\Test\\Anomaly\n",
    "# 348048\n",
    "# E:\\Dataset\\Test\\Normal\n",
    "# 137266\n",
    "# E:\\Dataset\\Train\\Anomaly\n",
    "# 1223394\n",
    "# E:\\Dataset\\Train\\Normal\n",
    "# 1151560\n",
    "\n",
    "\n",
    "\n",
    "# E:\\Dataset\\Test\\Anomaly\n",
    "# 275687\n",
    "# E:\\Dataset\\Test\\Normal\n",
    "# 137266\n",
    "# E:\\Dataset\\Train\\Anomaly\n",
    "# 958196\n",
    "# E:\\Dataset\\Train\\Normal\n",
    "# 1151560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"data/_training_logs/rnn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "##https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "\n",
    "\n",
    "model = build_feature_extractor()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "filepath=\"weights/Feature_Extractor2.h5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]\n",
    "# Train the model\n",
    "print('Now fitting')\n",
    "history = model.fit(\n",
    "              train_generator,\n",
    "              steps_per_epoch=train_generator.samples/64,\n",
    "              validation_data = val_generator,\n",
    "              validation_steps = val_generator.samples/64,\n",
    "              epochs=100,\n",
    "              callbacks=callbacks_list)\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show()\n",
    "# Save the trained model to disk\n",
    "model.save('weights/Feature_Extractor2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('weights/Feature_Extractor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "inp = model.input\n",
    "out = model.layers[-4].output\n",
    "feat_extractor = Model(inputs = [inp], outputs = [out])\n",
    "feat_extractor.summary()\n",
    "\n",
    "feat_extractor.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "LOOK_BACK = 4\n",
    "\n",
    "def seperate(POSITIVES_PATH):\n",
    "    data = np.array([])\n",
    "    numbers = []\n",
    "    # POSITIVE LABELS\n",
    "    for value in os.listdir(POSITIVES_PATH):\n",
    "#         print(value.split('_'))\n",
    "        \n",
    "        numbers.append(value.split('_')[1])\n",
    "#         print(numbers)\n",
    "    numbers=np.unique(numbers)\n",
    "    df = pd.DataFrame({'number':numbers, 'npDataFile':[\"-1\"]*len(numbers)})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    # filter by video\n",
    "def create_prediction(POSITIVES_PATH, numb, ind):\n",
    "    frames = []\n",
    "    data = np.array([])\n",
    "    # append image name\n",
    "\n",
    "    for value in os.listdir(POSITIVES_PATH):\n",
    "        if value.split('_')[1] == numb:\n",
    "            frames.append(value)\n",
    "\n",
    "    # sort image frame by frame number\n",
    "    \n",
    "    frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n",
    "    print(len(frames))\n",
    "    print(f'{ind} : {numb}')\n",
    "    image_data = np.zeros((len(frames), 256))\n",
    "        \n",
    "    for index, image in tqdm(enumerate(frames)):\n",
    "        img = cv2.imread(POSITIVES_PATH + image)\n",
    "        vect = feat_extractor.predict(img.reshape(1,224,224,3))\n",
    "        image_data[index,:] = vect\n",
    "\n",
    "    # for each frame get tensor with lookbacks\n",
    "    stacked_data = np.zeros((len(frames), look_back, 256))\n",
    "    for index in range(len(frames)):\n",
    "        stacked_data[index, 0, :] = image_data[index]\n",
    "        for lb in range(1, look_back):\n",
    "            if index - lb >= 0:\n",
    "                stacked_data[index, lb, :] = image_data[index - lb]\n",
    "            else:\n",
    "                stacked_data[index, lb, :] = np.zeros(256)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        return stacked_data\n",
    "    else:\n",
    "        return np.concatenate([data, stacked_data], axis = 0)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     for value in os.listdir(NEGATIVES_PATH):\n",
    "#         numbers.append(int(re.findall(r'\\d+', value.split('_')[2])[0]))\n",
    "\n",
    "#     # filter by video\n",
    "#     for numb in np.unique(numbers):\n",
    "#         frames = []\n",
    "#         # append image name\n",
    "#         for value in os.listdir(NEGATIVES_PATH):\n",
    "#             if int(re.findall(r'\\d+', value.split('_')[2])[0]) == numb:\n",
    "#                 frames.append(value)\n",
    "#         # sort image frame by frame number\n",
    "#         frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n",
    "#         image_data = np.zeros((len(frames), 1024))\n",
    "\n",
    "#         # get feature vector from vgg16 for each frame and stack\n",
    "#         for index, image in tqdm(enumerate(frames)):\n",
    "#             img = cv2.imread(NEGATIVES_PATH + image)\n",
    "#             vect = feat_extractor.predict(img.reshape(1,224,224,3))\n",
    "#             image_data[index,:] = vect\n",
    "\n",
    "#         # for each frame get tensor with lookbacks\n",
    "#         stacked_data = np.zeros((len(frames), look_back, 256))\n",
    "#         for index in tqdm(range(len(frames))):\n",
    "#             labels = np.append(labels, [0])\n",
    "#             stacked_data[index, 0, :] = image_data[index]\n",
    "#             for lb in range(1, look_back):\n",
    "#                 if index - lb >= 0:\n",
    "#                     stacked_data[index, lb, :] = image_data[index - lb]\n",
    "#                 else:\n",
    "#                     stacked_data[index, lb, :] = np.zeros(256)\n",
    "\n",
    "#         if data.shape[0] == 0:\n",
    "#             data = stacked_data\n",
    "#         else:\n",
    "#             data = np.concatenate([data, stacked_data], axis = 0)\n",
    "\n",
    "#     # one hot labels\n",
    "#     from keras.utils import to_categorical\n",
    "#     labels = to_categorical(labels)\n",
    "#     return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_labels = data_to_lstm_format(POSITIVES_PATH_TRAIN, NEGATIVES_PATH_TRAIN, look_back=LOOK_BACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TestNormaldf = seperate(POSITIVES_PATH_VALID)\n",
    "TestNormaldf = pd.read_csv('TestNormaldf.csv')\n",
    "TestNormaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainAno = pd.read_csv(\"AnomalyTrain.csv\")\n",
    "look_back = LOOK_BACK\n",
    "for i in TestNormaldf.index:\n",
    "    if TestNormaldf.at[i, 'npDataFile'] == \"-1\":\n",
    "        nparray = create_prediction(POSITIVES_PATH_VALID, TestNormaldf.at[i, 'number'], i)\n",
    "        filename = 'NPfiles/Test/Normal/'+str(TestNormaldf.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TestNormaldf.at[i,'npDataFile'] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestNormaldf.to_csv('TestNormaldf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TestAnomalydf = seperate(NEGATIVES_PATH_VALID)\n",
    "TestAnomalydf = pd.read_csv('TestAnomalydf.csv')\n",
    "TestAnomalydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "for i in TestAnomalydf.index:\n",
    "    if TestAnomalydf.at[i, 'npDataFile'] == \"-1\":\n",
    "        print(TestAnomalydf.at[i, 'number'])\n",
    "        nparray = create_prediction(NEGATIVES_PATH_VALID, TestAnomalydf.at[i, 'number'])\n",
    "        filename = 'NPfiles/Test/Anomaly/'+str(TestAnomalydf.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TestAnomalydf.at[i,'npDataFile'] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestAnomalydf.to_csv('TestAnomalydf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainNormaldf = seperate(POSITIVES_PATH_TRAIN)\n",
    "import pandas as pd\n",
    "TrainNormaldf = pd.read_csv('TrainNormaldf.csv')\n",
    "TrainNormaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "count = 0\n",
    "for i in TrainNormaldf.index:\n",
    "    if TrainNormaldf.at[i, 'npDataFile'] != \"-1\":\n",
    "        count += 1\n",
    "#         nparray = create_prediction(POSITIVES_PATH_TRAIN, TrainNormaldf.at[i, 'number'], i)\n",
    "#         filename = 'NPfiles/Train/Anomaly/'+str(TrainNormaldf.at[i, 'number'])\n",
    "#         np.save(filename, nparray)\n",
    "#         TrainNormaldf.at[i,'npDataFile'] = filename\n",
    "#         del nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainNormaldf.to_csv('TrainNormaldf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainNormaldf2 = seperate(NEGATIVES_PATH_TRAIN)\n",
    "TrainNormaldf2 = pd.read_csv('TrainNormaldf2.csv')\n",
    "TrainNormaldf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "for i in TrainNormaldf2.index:\n",
    "    if TrainNormaldf2.at[i, 'npDataFile'] == \"-1\" and i>144:\n",
    "        nparray = create_prediction(NEGATIVES_PATH_TRAIN, TrainNormaldf2.at[i, 'number'], i)\n",
    "        filename = 'NPfiles/Train/Normal/'+str(TrainNormaldf2.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TrainNormaldf2.at[i,'npDataFile'] = filename\n",
    "        del nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainNormaldf2.to_csv('TrainNormaldf2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_lstm_test1(): \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Test/Anomaly/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Test/Anomaly/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.ones(count)\n",
    "    return data, labels\n",
    "            \n",
    "            \n",
    "def prepare_for_lstm_test2():    \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Test/Normal/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Test/Normal/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.zeros(count)\n",
    "    return data, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1, val_labels1 = prepare_for_lstm_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data2, val_labels2 = prepare_for_lstm_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.concatenate([val_data1, val_data2], axis=0)\n",
    "val_labels = np.concatenate([val_labels1, val_labels2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"val_data.npy\", val_data)\n",
    "np.save(\"val_labels.npy\", val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_lstm_train1(): \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Train/Anomaly/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Train/Anomaly/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.ones(count)\n",
    "    return data, labels\n",
    "            \n",
    "            \n",
    "def prepare_for_lstm_train2():    \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Train/Normal/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Train/Normal/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.zeros(count)\n",
    "    return data, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1, train_labels1 = prepare_for_lstm_train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, train_labels2 = prepare_for_lstm_train2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate([train_data1, train_data2], axis=0)\n",
    "train_labels = np.concatenate([train_labels1, train_labels2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_data.npy\", train_data)\n",
    "np.save(\"train_labels.npy\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# val_data = np.load('val_data.npy')\n",
    "# val_labels = np.load('val_labels.npy')\n",
    "# train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "val_labels = to_categorical(val_labels)\n",
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "num_features = 256\n",
    "# def build_model():\n",
    "#     inp = L.Input(shape = (4, num_features))\n",
    "#     model = Sequential()\n",
    "#     model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(4, 256)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['acc'])\n",
    "#     return model\n",
    "\n",
    "def build_model():\n",
    "    inp = L.Input(shape = (4, num_features))\n",
    "    \n",
    "    \"\"\" Use CuDNNLSTM if your machine supports CUDA\n",
    "        Training time is significantly faster compared to LSTM \"\"\"\n",
    "    \n",
    "    #x = L.LSTM(64, return_sequences = True)(inp)tf.compat.v1.keras.layers.CuDNNLSTM\n",
    "    x = tf.compat.v1.keras.layers.CuDNNLSTM(64, return_sequences = True)(inp)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    #x = L.LSTM(16)(x)\n",
    "    x = tf.compat.v1.keras.layers.CuDNNLSTM(16)(x)\n",
    "    out = L.Dense(2, activation = 'softmax')(x)\n",
    "    model = Model(inputs = [inp], outputs = [out])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cad9037ad6b5c566\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cad9037ad6b5c566\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir data/_training_logs_2/rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "##https://www.tensorflow.org/tensorboard/get_started\n",
    "log_dir = \"data/_training_logs_2/rnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "callbacks_list = [tensorboard_callback]\n",
    "\n",
    "history = model.fit(train_data, train_labels, \n",
    "                    validation_data = (val_data, val_labels),\n",
    "                    callbacks = callbacks_list,\n",
    "                    verbose = 1, epochs = 20, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('weights/RNN_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('weights/RNN_2.h5')\n",
    "\n",
    "trainPredict = model.predict(train_data)\n",
    "testPredict = model.predict(val_data)\n",
    "\n",
    "# invert predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPredict = np.argmax(testPredict,axis=1)\n",
    "trainPredict = np.argmax(trainPredict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78    147595\n",
      "           1       0.80      0.85      0.82    172345\n",
      "\n",
      "    accuracy                           0.80    319940\n",
      "   macro avg       0.80      0.80      0.80    319940\n",
      "weighted avg       0.80      0.80      0.80    319940\n",
      "\n",
      "[[111124  36471]\n",
      " [ 26142 146203]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(testPredict, val_labels))\n",
    "print(confusion_matrix(testPredict, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  80.43  %\n",
      "f1_score :  0.805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "MNB_f1 = round(f1_score(val_labels, testPredict, average='weighted'), 3)\n",
    "MNB_accuracy = round((accuracy_score(val_labels, testPredict)*100),2)\n",
    "\n",
    "print(\"Accuracy : \" , MNB_accuracy , \" %\")\n",
    "print(\"f1_score : \" , MNB_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(\"D:/kunal/Project/Web Dev/media/blazedumes11j@gmail.com_06-02-2022-19-34-07.webm\")\n",
    "try:\n",
    "    while(True):\n",
    "\n",
    "        ret1,frame1= cap.read()\n",
    "        if not ret1:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "        cv2.imshow('window',frame1)\n",
    "        ret2,frame2=cap.read()\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "\n",
    "        deltaframe=cv2.absdiff(gray1,gray2)\n",
    "        cv2.imshow('delta',deltaframe)\n",
    "        threshold = cv2.threshold(deltaframe, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        threshold = cv2.dilate(threshold,None)\n",
    "        cv2.imshow('threshold',threshold)\n",
    "        countour,heirarchy = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in countour:\n",
    "            if cv2.contourArea(i) < 50:\n",
    "                continue\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(i)\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('window',frame2)\n",
    "\n",
    "        if cv2.waitKey(20) == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manDown(video_path, model, tracker):\n",
    "    frames = []\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    print(video_path)\n",
    "    try:\n",
    "        while True:\n",
    "            ok, image = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "\n",
    "            image = cv.resize(image, (700, 500))\n",
    "            booli, output = model.detect(image)\n",
    "            if(booli == False):\n",
    "                cv.imshow(\"image\", image)\n",
    "                frames.append(image)\n",
    "            else:\n",
    "                centroid_dict = dict() \n",
    "                objectId = 0\n",
    "                bboxes, confidences, class_ids = output\n",
    "                tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "                \n",
    "                for bb, conf, cid, trk in zip(bboxes, confidences, class_ids, tracks):\n",
    "                    if (model.checkPerson):\n",
    "                        xmin, ymin, xmax, ymax = model.convertBack(float(bb[0]), float(bb[1]), float(bb[2]), float(bb[3]))\n",
    "                        centroid_dict[objectId] = (int(bb[0]), int(bb[1]), xmin, ymin, xmax, ymax)\n",
    "                \n",
    "                    #print(tracks)\n",
    "                    objId = tracks[0]\n",
    "                    fall_alert_list = [] \n",
    "                    red_line_list = []\n",
    "                    for id,p in centroid_dict.items():\n",
    "                        dx, dy = p[4] - p[2], p[5] - p[3]  \n",
    "                        difference = dy-dx\n",
    "                        if difference < 0:\n",
    "                            fall_alert_list.append(id)      \n",
    "\n",
    "#                     for idx, box in centroid_dict.items():  # dict (1(key):red(value), 2 blue)  idx - key  box - value\n",
    "#                         if idx in fall_alert_list:   # if id is in red zone list\n",
    "#                             cv.rectangle(image, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) # Create Red bounding boxes  #starting point, ending point size of 2\n",
    "#                         else:\n",
    "#                             cv.rectangle(image, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2) \n",
    "\n",
    "                    if len(fall_alert_list)!=0:\n",
    "                        text = \"Fall Detected\"\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        text = \"Fall Not Detected\"\n",
    "                        alert_var = 0           # makes sure that alert is generated when there are 20 simultaeous frames of fall detection\n",
    "\n",
    "                    location = (10,25)\n",
    "                    if len(fall_alert_list)!=0:\n",
    "                        cv.putText(image, text, location, cv.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv.LINE_AA)  # Display Text\n",
    "                    else:\n",
    "                        cv.putText(image, text, location, cv.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv.LINE_AA)  # Display Text\n",
    "\n",
    "                    cv.imshow(\"image\", image)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    #return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manDown('fall.mp4', model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manDown(\"D:/kunal/Project/Web Dev/media/blazedumes11j@gmail.com_06-02-2022-19-34-07.webm\", model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, re, os, warnings, time\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "TAKE_FRAME = 1\n",
    "LOOK_BACK = 4\n",
    "VGG16_OUT = 256\n",
    "SIZE = (224, 224)\n",
    "#===============================================================================\n",
    "\"\"\" Config. for inference source and alert feature \"\"\"\n",
    "# Webcam on/off: If off, source will be test video path by default.\n",
    "FROM_WEBCAM = False\n",
    "# Email alert on/off.\n",
    "ALERT = False\n",
    "# Enter the mail to receive alerts. E.g., 'xxx@gmail.com'.\n",
    "MAIL = ''\n",
    "# Optimize the threshold (avg. prediction score for class labels) if desired.\n",
    "# 1 for class1 and 0 for class2. Currently set at 0.50 by default.\n",
    "Threshold = 0.70\n",
    "# Adjust the total_frames (avg. score to send the mail).\n",
    "# Currently set to 5 by default.\n",
    "positive_frames = 5\n",
    "CAM_CONSTANT = 0\n",
    "\n",
    "# CNN VGG model\n",
    "class FeatExtractor:\n",
    "    def __init__(self, SIZE):\n",
    "        self.size = SIZE\n",
    "        self.vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(self.size[0], self.size[1], 3))\n",
    "        for layer in self.vgg_conv.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Create the model\n",
    "        def build_feat_extractor():\n",
    "            model = models.Sequential()\n",
    "\n",
    "            # Add the vgg convolutional base model\n",
    "            model.add(self.vgg_conv)\n",
    "\n",
    "            # Add new layers\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(256, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.Dense(128, activation = 'relu'))\n",
    "            model.add(layers.Dense(2, activation='softmax'))\n",
    "            return model\n",
    "\n",
    "        self.model = build_feat_extractor()\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "        self.model.load_weights('weights/Feature_Extractor.h5')\n",
    "\n",
    "        inp = self.model.input\n",
    "        out = self.model.layers[-4].output\n",
    "        self.model = Model(inputs=[inp], outputs=[out])\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "    def get_feats(self, frames):\n",
    "        image_data = np.zeros((len(frames), VGG16_OUT))\n",
    "        for index, image in enumerate(frames):\n",
    "            vect = self.model.predict(image.reshape(1, self.size[0], self.size[1], 3))\n",
    "            image_data[index, :] = vect\n",
    "\n",
    "        image_data = image_data.reshape(1, len(frames), VGG16_OUT)\n",
    "        return image_data\n",
    "\n",
    "# RNN model\n",
    "class RnnModel:\n",
    "\n",
    "    def __init__(self, NUM_FEATURES, LOOK_BACK):\n",
    "        self.num_features = NUM_FEATURES\n",
    "        self.look_back = LOOK_BACK\n",
    "        def build_model():\n",
    "            inp = L.Input(shape=(self.look_back, self.num_features))\n",
    "            x = L.LSTM(64, return_sequences=True)(inp)\n",
    "            x = L.Dropout(0.2)(x)\n",
    "            x = L.LSTM(16)(x)\n",
    "\n",
    "            out = L.Dense(2, activation='softmax')(x)\n",
    "            model = Model(inputs=[inp], outputs=[out])\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=RMSprop(lr=1e-4),\n",
    "                          metrics=['acc'])\n",
    "            return model\n",
    "\n",
    "        self.model = build_model()\n",
    "        self.model.load_weights('weights/RNN_2.h5')\n",
    "\n",
    "    def predict(self, frame_data):\n",
    "        pred = self.model.predict(frame_data)\n",
    "        return pred[0][1]\n",
    "\n",
    "def __draw_label(img, text, pos, bg_color):\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.4\n",
    "    color = (0, 0, 0)\n",
    "    thickness = cv2.FILLED\n",
    "    margin = 2\n",
    "\n",
    "    txt_size = cv2.getTextSize(text, font_face, scale, thickness)\n",
    "\n",
    "    end_x = pos[0] + txt_size[0][0] + margin\n",
    "    end_y = pos[1] - txt_size[0][1] - margin\n",
    "\n",
    "    cv2.rectangle(img, pos, (end_x, end_y), bg_color, thickness)\n",
    "    cv2.putText(img, text, pos, font_face, scale, color, 1, cv2.LINE_AA)\n",
    "\n",
    "#===============================================================================\n",
    "# Initiate the main function\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cap = cv2.VideoCapture(\"C:/Users/admin/Downloads/Beirut-explosion-Video-shows-new-angle-of-the-massive-blast-YouTube.mp4\")\n",
    "    colorTracker = {}\n",
    "    cnt = 0\n",
    "    frames = []\n",
    "    fe = FeatExtractor(SIZE)\n",
    "    rnn = RnnModel(VGG16_OUT, LOOK_BACK)\n",
    "    total_frames = 0\n",
    "    detect_certainty = []\n",
    "    neg_certainty = []\n",
    "    while (cap.isOpened()):\n",
    "        cnt+=1\n",
    "        ret, full = cap.read()\n",
    "        image = cv2.resize(full, (700, 500))\n",
    "        booli, output = model.detect(image)\n",
    "        if(booli != False):\n",
    "            bboxes, confidences, class_ids = output\n",
    "            tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "\n",
    "            image, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "\n",
    "        image = autocrop(image)\n",
    "        frame = cv2.resize(image, (224, 224))\n",
    "        frame = frame[:, :, [2, 1, 0]]\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        frame = cv2.resize(frame, SIZE)\n",
    "        if cnt % TAKE_FRAME == 0:\n",
    "            frames.append(frame)\n",
    "            pred = 0\n",
    "            if len(frames) == LOOK_BACK:\n",
    "                # Get features\n",
    "                feats = fe.get_feats(frames)\n",
    "                frames.pop(0)\n",
    "                initial = time.time()\n",
    "                pred = rnn.predict(feats)\n",
    "                final = time.time() - initial\n",
    "#                 print(\"\")\n",
    "#                 # Check predictions per frame (either 0 or 1)\n",
    "#                 print('[INFO] Frame acc. predictions:', pred)\n",
    "#                 # Check inference time per frame\n",
    "#                 print('Frame inference in %.4f seconds' % (final))\n",
    "\n",
    "            if ret == True:\n",
    "                # Display the resulting frame\n",
    "                # Optimize the threshold (avg. prediction score for class labels) if desired\n",
    "                # 1 for class1 and 0 for class2. Please refer config.\n",
    "                if pred >= Threshold:\n",
    "                    __draw_label(image, 'Anomaly', (20, 20), (255, 255, 255))\n",
    "#                     print(\"ANomaly\")\n",
    "                    total_frames += 1\n",
    "                    detect_certainty.append(pred)\n",
    "                else:\n",
    "                    neg_certainty.append(pred)\n",
    "                    if ALERT:\n",
    "                        # Adjust the total_frames (avg. score to send the mail). Refer config.\n",
    "                        if total_frames > positive_frames:\n",
    "#                             print('[INFO] Sending mail...')\n",
    "                            neg = np.mean(neg_certainty)\n",
    "                            pos = np.mean(detect_certainty)\n",
    "                            time1 = total_frames * TAKE_FRAME / 30\n",
    "#                             Mailer().send(config.MAIL, total_frames, time1, pos, neg)\n",
    "#                             print('[INFO] Mail sent')\n",
    "                        detect_certainty = []\n",
    "                        total_frames = 0\n",
    "                    __draw_label(image, 'Normal', (20, 20), (255, 255, 255))\n",
    "                cv2.imshow('Test_Window', image)\n",
    "\n",
    "                # Press Q on keyboard to exit\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Break the loop\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
