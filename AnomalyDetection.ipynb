{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from motrackers.detectors import YOLOv3\n",
    "from motrackers import CentroidTracker, CentroidKF_Tracker, SORT, IOUTracker\n",
    "#from motrackers.utils import draw_tracks\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE = \"test.mp4\"\n",
    "WEIGHTS_PATH = './examples/pretrained_models/yolo_weights/yolov4.weights'\n",
    "CONFIG_FILE_PATH = './examples/pretrained_models/yolo_weights/yolov4.cfg'\n",
    "LABELS_PATH = \"./examples/pretrained_models/yolo_weights/coco_names.json\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "MAX_SEQ_LENGTH = 2000\n",
    "NUM_FEATURES = 2048\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.2\n",
    "DRAW_BOUNDING_BOXES = True\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracker = CentroidKF_Tracker(max_lost=0, tracker_output_format='mot_challenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv3(\n",
    "    weights_path=WEIGHTS_PATH,\n",
    "    configfile_path=CONFIG_FILE_PATH,\n",
    "    labels_path=LABELS_PATH,\n",
    "    confidence_threshold=CONFIDENCE_THRESHOLD,\n",
    "    nms_threshold=NMS_THRESHOLD,\n",
    "    draw_bboxes=DRAW_BOUNDING_BOXES,\n",
    "    use_gpu=USE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocrop(image, threshold=0):\n",
    "    if len(image.shape) == 3:\n",
    "        flatImage = np.max(image, 2)\n",
    "    else:\n",
    "        flatImage = image\n",
    "    assert len(flatImage.shape) == 2\n",
    "\n",
    "    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n",
    "    if rows.size:\n",
    "        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n",
    "        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n",
    "    else:\n",
    "        image = image[:1, :1]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(video_path, model, tracker):\n",
    "    frames = []\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    colorTracker = {}\n",
    "    trk_dict={}\n",
    "    count = 0\n",
    "    prev_frame_time = 0\n",
    "    new_frame_time = 0\n",
    "    try:\n",
    "        while True:\n",
    "            ok, image = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "            \n",
    "            image = cv.resize(image, (700, 500))\n",
    "            booli, output = model.detect(image)\n",
    "            #print('below detect')\n",
    "            if(booli != False):\n",
    "                bboxes, confidences, class_ids = output\n",
    "                tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "                #print(class_ids)\n",
    "                #print('below tracking')\n",
    "                image, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "                #print('below drawing')\n",
    "                \n",
    "                #frame = crop_center_square(updated_image)\n",
    "#             gray = cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "#             _,thresh = cv.threshold(gray,1,255,cv.THRESH_BINARY)\n",
    "#             contours,hierarchy = cv.findContours(thresh,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "#             cnt = contours[0]\n",
    "#             x,y,w,h = cv.boundingRect(cnt)\n",
    "#             frame = image[y:y+h,x:x+w]\n",
    "            #print(image.shape)\n",
    "            image = autocrop(image)\n",
    "            frame = cv.resize(image, (224, 224))\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "            #print('below resize')\n",
    "           # frame = frame[20:210, 10:210]\n",
    "            frames.append(frame)\n",
    "            #print('below append')\n",
    "            count += 1\n",
    "            #print(count)\n",
    "            #print(type(frames))\n",
    "            #print(f'{count}-{fps}')\n",
    "            cv.imshow(\"image\", frame)\n",
    "            #print('below show')\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    return np.array(frames)\n",
    "main('test/test.mp4', model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dir(path):\n",
    "#     try:\n",
    "#         os.stat(path)\n",
    "#     except:\n",
    "#         os.mkdir(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_dirs():\n",
    "#     create_dir('E:/dataset/')\n",
    "#     create_dir('E:/dataset/Train/')\n",
    "#     create_dir('E:/dataset/Test')\n",
    "#     create_dir('E:/dataset/Train/Anomaly/')\n",
    "#     create_dir('E:/dataset/Test/Anomaly/')\n",
    "#     create_dir('E:/dataset/Train/Normal/')\n",
    "#     create_dir('E:/dataset/Test/Normal/')\n",
    "# initialize_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(start_path = 'data/'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainAno = pd.read_csv(\"AnomalyTrain.csv\")\n",
    "for i in trainAno.index:\n",
    "    if trainAno.at[i, 'progress'] == -1:\n",
    "        vid = trainAno.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Train/Anomaly/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        trainAno.at[i, 'progress'] = 1\n",
    "        trainAno.at[i, 'count'] = count\n",
    "        trainAno.to_csv('AnomalyTrain.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testAno = pd.read_csv(\"AnomalyTest.csv\")\n",
    "for i in testAno.index:\n",
    "    if testAno.at[i, 'progress'] == -1:\n",
    "        vid = testAno.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Test/Anomaly/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        testAno.at[i, 'progress'] = 1\n",
    "        testAno.at[i, 'count'] = count\n",
    "        testAno.to_csv('AnomalyTest.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNor = pd.read_csv(\"NormalTrain.csv\")\n",
    "for i in testNor.index:\n",
    "    if testNor.at[i, 'progress'] == -1:\n",
    "        vid = testNor.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Test/Normal/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        testNor.at[i, 'progress'] = 1\n",
    "        testNor.at[i, 'count'] = count\n",
    "        testNor.to_csv('NormalTrain.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNor = pd.read_csv(\"NormalTest.csv\")\n",
    "print(trainNor.index)\n",
    "for i in trainNor.index:\n",
    "    if trainNor.at[i, 'progress'] == -1:\n",
    "        vid = trainNor.at[i, 'path']\n",
    "        print(vid)\n",
    "        frames = main(vid, model, tracker)\n",
    "        count = 0\n",
    "        for j in frames:\n",
    "            cv.imwrite('E:/dataset/Train/Normal/' + vid.split('\\\\')[-1].split('.')[0]+f'_frame{count}.jpg', j)\n",
    "            count+=1\n",
    "        trainNor.at[i, 'progress'] = 1\n",
    "        trainNor.at[i, 'count'] = count\n",
    "        trainNor.to_csv('NormalTest.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import cv2 as cv\n",
    "# frames = []\n",
    "# colorTracker = {}\n",
    "# image = cv.imread(\"street2.jpg\")\n",
    "# image = cv.resize(image, (700, 500))\n",
    "# booli, output = model.detect(image)\n",
    "# if(booli == False):\n",
    "#     frame = cv.resize(output, (224, 224))\n",
    "#     #print(f'false:{count}')\n",
    "# else:\n",
    "#     bboxes, confidences, class_ids = output\n",
    "#     tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "#     #print(class_ids)\n",
    "# #             print(len(tracks))\n",
    "#     frame, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "#     frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "#     fig = plt.figure(figsize=(12,7))\n",
    "#     plt.imshow(frame)\n",
    "# # frame = frame[20:210, 10:210]\n",
    "# #print(count)\n",
    "# #print(type(frames))\n",
    "# #print(f'{count}-{fps}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig('obj2.jpg', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices()) # list of DeviceAttributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (224,224)\n",
    "NEGATIVES_PATH_TRAIN = 'E:/dataset/Train/Normal/'\n",
    "POSITIVES_PATH_TRAIN = 'E:/dataset/Train/Anomaly/'\n",
    "POSITIVES_PATH_VALID = 'E:/dataset/Test/Normal/'\n",
    "NEGATIVES_PATH_VALID = 'E:/dataset/Test/Anomaly/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_conv.summary()\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.plot_model(vgg_conv, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Add the vgg convolutional base model\n",
    "    model.add(vgg_conv)\n",
    "\n",
    "    # Add new layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(128, activation = 'relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "build_feature_extractor().summary()\n",
    "tf.keras.utils.plot_model(build_feature_extractor(), to_file='model2.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_batchsize = 16\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator = train_datagen.flow_from_directory('E:/dataset/Train/', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "val_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "val_generator = val_datagen.flow_from_directory('E:/dataset/Test/', class_mode='categorical', batch_size=train_batchsize, target_size = SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E:\\Dataset\\Test\\Anomaly\n",
    "# 348048\n",
    "# E:\\Dataset\\Test\\Normal\n",
    "# 137266\n",
    "# E:\\Dataset\\Train\\Anomaly\n",
    "# 1223394\n",
    "# E:\\Dataset\\Train\\Normal\n",
    "# 1151560\n",
    "\n",
    "\n",
    "\n",
    "# E:\\Dataset\\Test\\Anomaly\n",
    "# 275687\n",
    "# E:\\Dataset\\Test\\Normal\n",
    "# 137266\n",
    "# E:\\Dataset\\Train\\Anomaly\n",
    "# 958196\n",
    "# E:\\Dataset\\Train\\Normal\n",
    "# 1151560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "##https://www.tensorflow.org/tensorboard/get_started\n",
    "\n",
    "\n",
    "\n",
    "model = build_feature_extractor()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "filepath=\"weights/Feature_Extractor2.h5\"\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]\n",
    "# Train the model\n",
    "print('Now fitting')\n",
    "history = model.fit(\n",
    "              train_generator,\n",
    "              steps_per_epoch=train_generator.samples/64,\n",
    "              validation_data = val_generator,\n",
    "              validation_steps = val_generator.samples/64,\n",
    "              epochs=100,\n",
    "              callbacks=callbacks_list)\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.show()\n",
    "# Save the trained model to disk\n",
    "model.save('weights/Feature_Extractor2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('weights/Feature_Extractor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "inp = model.input\n",
    "out = model.layers[-4].output\n",
    "feat_extractor = Model(inputs = [inp], outputs = [out])\n",
    "feat_extractor.summary()\n",
    "\n",
    "feat_extractor.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "LOOK_BACK = 4\n",
    "\n",
    "def seperate(POSITIVES_PATH):\n",
    "    data = np.array([])\n",
    "    numbers = []\n",
    "    # POSITIVE LABELS\n",
    "    for value in os.listdir(POSITIVES_PATH):\n",
    "#         print(value.split('_'))\n",
    "        \n",
    "        numbers.append(value.split('_')[1])\n",
    "#         print(numbers)\n",
    "    numbers=np.unique(numbers)\n",
    "    df = pd.DataFrame({'number':numbers, 'npDataFile':[\"-1\"]*len(numbers)})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    # filter by video\n",
    "def create_prediction(POSITIVES_PATH, numb, ind):\n",
    "    frames = []\n",
    "    data = np.array([])\n",
    "    # append image name\n",
    "\n",
    "    for value in os.listdir(POSITIVES_PATH):\n",
    "        if value.split('_')[1] == numb:\n",
    "            frames.append(value)\n",
    "\n",
    "    # sort image frame by frame number\n",
    "    \n",
    "    frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n",
    "    print(len(frames))\n",
    "    print(f'{ind} : {numb}')\n",
    "    image_data = np.zeros((len(frames), 256))\n",
    "        \n",
    "    for index, image in tqdm(enumerate(frames)):\n",
    "        img = cv2.imread(POSITIVES_PATH + image)\n",
    "        vect = feat_extractor.predict(img.reshape(1,224,224,3))\n",
    "        image_data[index,:] = vect\n",
    "\n",
    "    # for each frame get tensor with lookbacks\n",
    "    stacked_data = np.zeros((len(frames), look_back, 256))\n",
    "    for index in range(len(frames)):\n",
    "        stacked_data[index, 0, :] = image_data[index]\n",
    "        for lb in range(1, look_back):\n",
    "            if index - lb >= 0:\n",
    "                stacked_data[index, lb, :] = image_data[index - lb]\n",
    "            else:\n",
    "                stacked_data[index, lb, :] = np.zeros(256)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        return stacked_data\n",
    "    else:\n",
    "        return np.concatenate([data, stacked_data], axis = 0)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     for value in os.listdir(NEGATIVES_PATH):\n",
    "#         numbers.append(int(re.findall(r'\\d+', value.split('_')[2])[0]))\n",
    "\n",
    "#     # filter by video\n",
    "#     for numb in np.unique(numbers):\n",
    "#         frames = []\n",
    "#         # append image name\n",
    "#         for value in os.listdir(NEGATIVES_PATH):\n",
    "#             if int(re.findall(r'\\d+', value.split('_')[2])[0]) == numb:\n",
    "#                 frames.append(value)\n",
    "#         # sort image frame by frame number\n",
    "#         frames = sorted(frames, key = lambda x: int(re.findall(r'\\d+', x.split('_')[-1].split('.')[0])[0]))\n",
    "#         image_data = np.zeros((len(frames), 1024))\n",
    "\n",
    "#         # get feature vector from vgg16 for each frame and stack\n",
    "#         for index, image in tqdm(enumerate(frames)):\n",
    "#             img = cv2.imread(NEGATIVES_PATH + image)\n",
    "#             vect = feat_extractor.predict(img.reshape(1,224,224,3))\n",
    "#             image_data[index,:] = vect\n",
    "\n",
    "#         # for each frame get tensor with lookbacks\n",
    "#         stacked_data = np.zeros((len(frames), look_back, 256))\n",
    "#         for index in tqdm(range(len(frames))):\n",
    "#             labels = np.append(labels, [0])\n",
    "#             stacked_data[index, 0, :] = image_data[index]\n",
    "#             for lb in range(1, look_back):\n",
    "#                 if index - lb >= 0:\n",
    "#                     stacked_data[index, lb, :] = image_data[index - lb]\n",
    "#                 else:\n",
    "#                     stacked_data[index, lb, :] = np.zeros(256)\n",
    "\n",
    "#         if data.shape[0] == 0:\n",
    "#             data = stacked_data\n",
    "#         else:\n",
    "#             data = np.concatenate([data, stacked_data], axis = 0)\n",
    "\n",
    "#     # one hot labels\n",
    "#     from keras.utils import to_categorical\n",
    "#     labels = to_categorical(labels)\n",
    "#     return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_labels = data_to_lstm_format(POSITIVES_PATH_TRAIN, NEGATIVES_PATH_TRAIN, look_back=LOOK_BACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TestNormaldf = seperate(POSITIVES_PATH_VALID)\n",
    "TestNormaldf = pd.read_csv('TestNormaldf.csv')\n",
    "TestNormaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainAno = pd.read_csv(\"AnomalyTrain.csv\")\n",
    "look_back = LOOK_BACK\n",
    "for i in TestNormaldf.index:\n",
    "    if TestNormaldf.at[i, 'npDataFile'] == \"-1\":\n",
    "        nparray = create_prediction(POSITIVES_PATH_VALID, TestNormaldf.at[i, 'number'], i)\n",
    "        filename = 'NPfiles/Test/Normal/'+str(TestNormaldf.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TestNormaldf.at[i,'npDataFile'] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TestNormaldf.to_csv('TestNormaldf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TestAnomalydf = seperate(NEGATIVES_PATH_VALID)\n",
    "TestAnomalydf = pd.read_csv('TestAnomalydf.csv')\n",
    "TestAnomalydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "for i in TestAnomalydf.index:\n",
    "    if TestAnomalydf.at[i, 'npDataFile'] == \"-1\":\n",
    "        print(TestAnomalydf.at[i, 'number'])\n",
    "        nparray = create_prediction(NEGATIVES_PATH_VALID, TestAnomalydf.at[i, 'number'])\n",
    "        filename = 'NPfiles/Test/Anomaly/'+str(TestAnomalydf.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TestAnomalydf.at[i,'npDataFile'] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestAnomalydf.to_csv('TestAnomalydf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TrainNormaldf = seperate(POSITIVES_PATH_TRAIN)\n",
    "import pandas as pd\n",
    "TrainNormaldf = pd.read_csv('TrainNormaldf.csv')\n",
    "TrainNormaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "count = 0\n",
    "for i in TrainNormaldf.index:\n",
    "    if TrainNormaldf.at[i, 'npDataFile'] != \"-1\":\n",
    "        count += 1\n",
    "#         nparray = create_prediction(POSITIVES_PATH_TRAIN, TrainNormaldf.at[i, 'number'], i)\n",
    "#         filename = 'NPfiles/Train/Anomaly/'+str(TrainNormaldf.at[i, 'number'])\n",
    "#         np.save(filename, nparray)\n",
    "#         TrainNormaldf.at[i,'npDataFile'] = filename\n",
    "#         del nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainNormaldf.to_csv('TrainNormaldf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainNormaldf2 = seperate(NEGATIVES_PATH_TRAIN)\n",
    "TrainNormaldf2 = pd.read_csv('TrainNormaldf2.csv')\n",
    "TrainNormaldf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "look_back = LOOK_BACK\n",
    "for i in TrainNormaldf2.index:\n",
    "    if TrainNormaldf2.at[i, 'npDataFile'] == \"-1\" and i>144:\n",
    "        nparray = create_prediction(NEGATIVES_PATH_TRAIN, TrainNormaldf2.at[i, 'number'], i)\n",
    "        filename = 'NPfiles/Train/Normal/'+str(TrainNormaldf2.at[i, 'number'])\n",
    "        np.save(filename, nparray)\n",
    "        TrainNormaldf2.at[i,'npDataFile'] = filename\n",
    "        del nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainNormaldf2.to_csv('TrainNormaldf2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_for_lstm_test1(): \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Test/Anomaly/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Test/Anomaly/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.ones(count)\n",
    "    return data, labels\n",
    "            \n",
    "            \n",
    "def prepare_for_lstm_test2():    \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Test/Normal/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Test/Normal/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.zeros(count)\n",
    "    return data, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data1, val_labels1 = prepare_for_lstm_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data2, val_labels2 = prepare_for_lstm_test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.concatenate([val_data1, val_data2], axis=0)\n",
    "val_labels = np.concatenate([val_labels1, val_labels2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"val_data.npy\", val_data)\n",
    "np.save(\"val_labels.npy\", val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_lstm_train1(): \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Train/Anomaly/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Train/Anomaly/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.ones(count)\n",
    "    return data, labels\n",
    "            \n",
    "            \n",
    "def prepare_for_lstm_train2():    \n",
    "    count = 0\n",
    "    data = np.array([])\n",
    "    for values in tqdm(os.listdir('NPfiles/Train/Normal/')):\n",
    "        stacked_data = np.load(os.path.join('NPfiles/Train/Normal/', values))\n",
    "        count += len(stacked_data)\n",
    "        if data.shape[0] == 0:\n",
    "            data = stacked_data\n",
    "        else:\n",
    "            data = np.concatenate([data, stacked_data], axis = 0)\n",
    "    labels = np.zeros(count)\n",
    "    return data, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1, train_labels1 = prepare_for_lstm_train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, train_labels2 = prepare_for_lstm_train2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate([train_data1, train_data2], axis=0)\n",
    "train_labels = np.concatenate([train_labels1, train_labels2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_data.npy\", train_data)\n",
    "np.save(\"train_labels.npy\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# val_data = np.load('val_data.npy')\n",
    "# val_labels = np.load('val_labels.npy')\n",
    "# train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "val_labels = to_categorical(val_labels)\n",
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout\n",
    "num_features = 256\n",
    "# def build_model():\n",
    "#     inp = L.Input(shape = (4, num_features))\n",
    "#     model = Sequential()\n",
    "#     model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(4, 256)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Bidirectional(LSTM(16, return_sequences=True)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['acc'])\n",
    "#     return model\n",
    "\n",
    "def build_model():\n",
    "    inp = L.Input(shape = (4, num_features))\n",
    "    \n",
    "    \"\"\" Use CuDNNLSTM if your machine supports CUDA\n",
    "        Training time is significantly faster compared to LSTM \"\"\"\n",
    "    \n",
    "    #x = L.LSTM(64, return_sequences = True)(inp)tf.compat.v1.keras.layers.CuDNNLSTM\n",
    "    x = tf.compat.v1.keras.layers.CuDNNLSTM(64, return_sequences = True)(inp)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    #x = L.LSTM(16)(x)\n",
    "    x = tf.compat.v1.keras.layers.CuDNNLSTM(16)(x)\n",
    "    out = L.Dense(2, activation = 'softmax')(x)\n",
    "    model = Model(inputs = [inp], outputs = [out])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a52764551a351693\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a52764551a351693\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir data/_training_logs_2/rnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "##https://www.tensorflow.org/tensorboard/get_started\n",
    "log_dir = \"data/_training_logs_2/rnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
    "callbacks_list = [tensorboard_callback]\n",
    "\n",
    "history = model.fit(train_data, train_labels, \n",
    "                    validation_data = (val_data, val_labels),\n",
    "                    callbacks = callbacks_list,\n",
    "                    verbose = 1, epochs = 20, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('weights/RNN_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('weights/RNN_2.h5')\n",
    "\n",
    "trainPredict = model.predict(train_data)\n",
    "testPredict = model.predict(val_data)\n",
    "\n",
    "# invert predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPredict = np.argmax(testPredict,axis=1)\n",
    "trainPredict = np.argmax(trainPredict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78    147595\n",
      "           1       0.80      0.85      0.82    172345\n",
      "\n",
      "    accuracy                           0.80    319940\n",
      "   macro avg       0.80      0.80      0.80    319940\n",
      "weighted avg       0.80      0.80      0.80    319940\n",
      "\n",
      "[[111124  36471]\n",
      " [ 26142 146203]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(testPredict, val_labels))\n",
    "print(confusion_matrix(testPredict, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  80.43  %\n",
      "f1_score :  0.805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "MNB_f1 = round(f1_score(val_labels, testPredict, average='weighted'), 3)\n",
    "MNB_accuracy = round((accuracy_score(val_labels, testPredict)*100),2)\n",
    "\n",
    "print(\"Accuracy : \" , MNB_accuracy , \" %\")\n",
    "print(\"f1_score : \" , MNB_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(\"test/test.mp4\")\n",
    "try:\n",
    "    while(True):\n",
    "\n",
    "        ret1,frame1= cap.read()\n",
    "        if not ret1:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "        \n",
    "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        gray1 = cv2.GaussianBlur(gray1, (21, 21), 0)\n",
    "        ret2,frame2=cap.read()\n",
    "        temp = cv2.resize(frame2, (350, 200))\n",
    "        cv2.imshow('input',temp)\n",
    "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "        gray2 = cv2.GaussianBlur(gray2, (21, 21), 0)\n",
    "        deltaframe=cv2.absdiff(gray1,gray2)\n",
    "#         cv2.imshow('delta',deltaframe)\n",
    "        threshold = cv2.threshold(deltaframe, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "        threshold = cv2.dilate(threshold,None)\n",
    "        temp2 = cv2.resize(threshold, (350, 200))\n",
    "        cv2.imshow('threshold',temp2)\n",
    "        countour,heirarchy = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for i in countour:\n",
    "            if cv2.contourArea(i) < 50:\n",
    "                continue\n",
    "\n",
    "            (x, y, w, h) = cv2.boundingRect(i)\n",
    "            cv2.rectangle(frame2, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        cv.putText(frame2, \"Motion Detected\", (10,25), cv.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv.LINE_AA)\n",
    "        temp3 = cv2.resize(frame2, (350, 200))\n",
    "        cv2.imshow('window',temp3)\n",
    "\n",
    "        if cv2.waitKey(20) == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manDown(video_path, model, tracker):\n",
    "    frames = []\n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    print(video_path)\n",
    "    try:\n",
    "        while True:\n",
    "            ok, image = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                print(\"Cannot read the video feed.\")\n",
    "                break\n",
    "\n",
    "            image = cv.resize(image, (700, 500))\n",
    "            booli, output = model.detect(image)\n",
    "            if(booli == False):\n",
    "                cv.imshow(\"image\", image)\n",
    "                frames.append(image)\n",
    "            else:\n",
    "                centroid_dict = dict() \n",
    "                objectId = 0\n",
    "                bboxes, confidences, class_ids = output\n",
    "                tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "                \n",
    "                for bb, conf, cid, trk in zip(bboxes, confidences, class_ids, tracks):\n",
    "                    if (model.checkPerson):\n",
    "                        xmin, ymin, xmax, ymax = model.convertBack(float(bb[0]), float(bb[1]), float(bb[2]), float(bb[3]))\n",
    "                        centroid_dict[objectId] = (int(bb[0]), int(bb[1]), xmin, ymin, xmax, ymax)\n",
    "                \n",
    "                    #print(tracks)\n",
    "                    objId = tracks[0]\n",
    "                    fall_alert_list = [] \n",
    "                    red_line_list = []\n",
    "                    for id,p in centroid_dict.items():\n",
    "                        dx, dy = p[4] - p[2], p[5] - p[3]  \n",
    "                        difference = dy-dx\n",
    "                        if difference < 0:\n",
    "                            fall_alert_list.append(id)      \n",
    "\n",
    "#                     for idx, box in centroid_dict.items():  # dict (1(key):red(value), 2 blue)  idx - key  box - value\n",
    "#                         if idx in fall_alert_list:   # if id is in red zone list\n",
    "#                             cv.rectangle(image, (box[2], box[3]), (box[4], box[5]), (255, 0, 0), 2) # Create Red bounding boxes  #starting point, ending point size of 2\n",
    "#                         else:\n",
    "#                             cv.rectangle(image, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2) \n",
    "\n",
    "                    if len(fall_alert_list)!=0:\n",
    "                        text = \"Fall Detected\"\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        text = \"Fall Not Detected\"\n",
    "                        alert_var = 0           # makes sure that alert is generated when there are 20 simultaeous frames of fall detection\n",
    "\n",
    "                    location = (10,25)\n",
    "                    if len(fall_alert_list)!=0:\n",
    "                        cv.putText(image, text, location, cv.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv.LINE_AA)  # Display Text\n",
    "                    else:\n",
    "                        cv.putText(image, text, location, cv.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv.LINE_AA)  # Display Text\n",
    "\n",
    "                    cv.imshow(\"image\", image)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    #return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manDown('test/fall.mp4', model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, re, os, warnings, time\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "TAKE_FRAME = 1\n",
    "LOOK_BACK = 4\n",
    "VGG16_OUT = 256\n",
    "SIZE = (224, 224)\n",
    "\n",
    "FROM_WEBCAM = False\n",
    "ALERT = False\n",
    "Threshold = 0.60\n",
    "\n",
    "positive_frames = 5\n",
    "CAM_CONSTANT = 0\n",
    "\n",
    "class FeatExtractor:\n",
    "    def __init__(self, SIZE):\n",
    "        self.size = SIZE\n",
    "        self.vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(self.size[0], self.size[1], 3))\n",
    "        for layer in self.vgg_conv.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        def build_feat_extractor():\n",
    "            model = models.Sequential()\n",
    "            model.add(self.vgg_conv)\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(256, activation='relu'))\n",
    "            model.add(layers.Dropout(0.2))\n",
    "            model.add(layers.Dense(128, activation = 'relu'))\n",
    "            model.add(layers.Dense(2, activation='softmax'))\n",
    "            return model\n",
    "\n",
    "        self.model = build_feat_extractor()\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "        self.model.load_weights('weights/Feature_Extractor.h5')\n",
    "\n",
    "        inp = self.model.input\n",
    "        out = self.model.layers[-4].output\n",
    "        self.model = Model(inputs=[inp], outputs=[out])\n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "    def get_feats(self, frames):\n",
    "        image_data = np.zeros((len(frames), VGG16_OUT))\n",
    "        for index, image in enumerate(frames):\n",
    "            vect = self.model.predict(image.reshape(1, self.size[0], self.size[1], 3))\n",
    "            image_data[index, :] = vect\n",
    "\n",
    "        image_data = image_data.reshape(1, len(frames), VGG16_OUT)\n",
    "        return image_data\n",
    "\n",
    "class RnnModel:\n",
    "\n",
    "    def __init__(self, NUM_FEATURES, LOOK_BACK):\n",
    "        self.num_features = NUM_FEATURES\n",
    "        self.look_back = LOOK_BACK\n",
    "        def build_model():\n",
    "            inp = L.Input(shape=(self.look_back, self.num_features))\n",
    "            x = L.LSTM(64, return_sequences=True)(inp)\n",
    "            x = L.Dropout(0.2)(x)\n",
    "            x = L.LSTM(16)(x)\n",
    "\n",
    "            out = L.Dense(2, activation='softmax')(x)\n",
    "            model = Model(inputs=[inp], outputs=[out])\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=RMSprop(lr=1e-4),\n",
    "                          metrics=['acc'])\n",
    "            return model\n",
    "\n",
    "        self.model = build_model()\n",
    "        self.model.load_weights('weights/RNN_2.h5')\n",
    "\n",
    "    def predict(self, frame_data):\n",
    "        pred = self.model.predict(frame_data)\n",
    "        return pred[0][1]\n",
    "\n",
    "def __draw_label(img, text, pos, bg_color):\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 1\n",
    "    color = (0, 0, 0)\n",
    "    thickness = cv2.FILLED\n",
    "    margin = 6\n",
    "\n",
    "    txt_size = cv2.getTextSize(text, font_face, scale, thickness)\n",
    "\n",
    "    end_x = pos[0] + txt_size[0][0] + margin\n",
    "    end_y = pos[1] - txt_size[0][1] - margin\n",
    "\n",
    "    cv2.rectangle(img, pos, (end_x, end_y), bg_color, thickness)\n",
    "    cv2.putText(img, text, pos, font_face, scale, color, 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    prediction=[]\n",
    "    cap = cv2.VideoCapture(\"test/test.mp4\")\n",
    "    colorTracker = {}\n",
    "    cnt = 0\n",
    "    frames = []\n",
    "    fe = FeatExtractor(SIZE)\n",
    "    rnn = RnnModel(VGG16_OUT, LOOK_BACK)\n",
    "    total_frames = 0\n",
    "    detect_certainty = []\n",
    "    neg_certainty = []\n",
    "    rval, frame = cap.read()\n",
    "#     media_path = settings.MEDIA_ROOT\n",
    "    # frame_size = (int(cap.get(3)), int(cap.get(4)))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "#     filename = f\"test_processed_fall.webm\"\n",
    "    file_location = \"processed_normal.mp4\"\n",
    "    out = cv2.VideoWriter(file_location, fourcc, 30, (700, 500))\n",
    "    while (cap.isOpened()):\n",
    "        cnt+=1\n",
    "        ret, full = cap.read()\n",
    "        if ret == True:\n",
    "            image = cv2.resize(full, (700, 500))\n",
    "            booli, output = model.detect(image)\n",
    "            if(booli != False):\n",
    "                bboxes, confidences, class_ids = output\n",
    "                tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "\n",
    "                image, colorTracker = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids, tracks, colorTracker)\n",
    "\n",
    "            image = autocrop(image)\n",
    "            frame = cv2.resize(image, (224, 224))\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            frame = cv2.resize(frame, SIZE)\n",
    "            if cnt % TAKE_FRAME == 0:\n",
    "                frames.append(frame)\n",
    "                pred = 0\n",
    "                if len(frames) == LOOK_BACK:\n",
    "                    feats = fe.get_feats(frames)\n",
    "                    frames.pop(0)\n",
    "                    initial = time.time()\n",
    "                    pred = rnn.predict(feats)\n",
    "                    final = time.time() - initial\n",
    "    #                 print(\"\")\n",
    "    #                 print('[INFO] Frame acc. predictions:', pred)\n",
    "    #                 print('Frame inference in %.4f seconds' % (final))\n",
    "            if pred >= Threshold:\n",
    "                __draw_label(image, 'Anomaly_Score: {:.2f}'.format(pred), (5, 30), (255, 255, 255))\n",
    "#                     print(\"ANomaly\")\n",
    "                total_frames += 1\n",
    "                detect_certainty.append(pred)\n",
    "            else:\n",
    "                neg_certainty.append(pred)\n",
    "                if ALERT:\n",
    "                    if total_frames > positive_frames:\n",
    "                        neg = np.mean(neg_certainty)\n",
    "                        pos = np.mean(detect_certainty)\n",
    "                        time1 = total_frames * TAKE_FRAME / 30                          \n",
    "                    detect_certainty = []\n",
    "                    total_frames = 0\n",
    "                __draw_label(image, 'Normal_Score: {:.2f}'.format(pred), (5, 30), (255, 255, 255))\n",
    "           \n",
    "            __draw_label(image, f\"Frame: {cnt}\", (400, 30), (255, 255, 255))\n",
    "            cv2.imshow('Test_Window', image)\n",
    "            out.write(image)\n",
    "            prediction.append(pred)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenn = [x for x in range(0, len(prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lenn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHkCAYAAAAuKRZVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACGlElEQVR4nO29d5wkZ33n/3m6q/Pk2ZxX0iqshBBKRCOSTbTleGAcMNiH+RmcsH3G+OyzzfnufLYPHAjGJPtszGEDRoAMNgIBEkEoZ7Gr3dVG7e7MTu5YVc/vj6qnurq6qrp6pqu7a+bzfr32tTM9Pd1P11TV5/lmIaUEIYQQQpJHatALIIQQQsjqoIgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJJTYRF0J8RAhxTgjxcMDPhRDiL4UQh4UQDwohro1rLYQQQsh6JE5L/GMAXhHy81cCOGD/ezOA98e4FkIIIWTdEZuISym/DuBCyFNuBvD30uLbACaEENvjWg8hhBCy3hhkTHwngBOu70/ajxFCCCEkAtoA31v4PObbA1YI8WZYLneUSqXrLr/88jjXRQghhAwV99xzz4yUcrP38UGK+EkAu13f7wJw2u+JUsoPAvggAFx//fXy7rvvjn91hBBCyJAghHjK7/FButNvAfCzdpb6cwAsSCnPDHA9hBBCSKKIzRIXQvwTgBcB2CSEOAngvwHIAICU8gMAbgXwKgCHAZQBvDGutRBCCCHrkdhEXEr5kx1+LgG8Na73J4QQQtY77NhGCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklBiFXEhxCuEEE8IIQ4LId7h8/NxIcTnhBAPCCEeEUK8Mc71EEIIIeuJ2ERcCJEG8F4ArwRwEMBPCiEOep72VgCPSimfCeBFAP5cCJGNa02EEELIeiJOS/xGAIellEeklHUAnwBws+c5EsCoEEIAGAFwAYAe45oIIYSQdUOcIr4TwAnX9yftx9z8NYArAJwG8BCAX5VSmjGuiRBCCFk3xCniwucx6fn+5QDuB7ADwDUA/loIMdb2QkK8WQhxtxDi7vPnz/d6nYQQQkgiiVPETwLY7fp+FyyL280bAXxaWhwGcBTA5d4XklJ+UEp5vZTy+s2bN8e2YEIIISRJxCni3wVwQAix305Wex2AWzzPOQ7gpQAghNgK4DIAR2JcEyGEELJu0OJ6YSmlLoR4G4AvAUgD+IiU8hEhxFvsn38AwLsAfEwI8RAs9/tvSyln4loTIYQQsp6ITcQBQEp5K4BbPY99wPX1aQA/EOcaCCGEkPUKO7YRQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQqGIE0IIIQmFIk4IIYQkFIo4IYQQklAo4oQQQkhCoYgTQkgHHj61gMefXhz0MghpgyJOCCEd+MPPPYI//sJjg14GIW1og14AIYQMO0tVHQ1DDnoZhLRBESeEkA7UdBOmpIiT4YMiTgghHag2DNR1MehlENIGRZwQQjpQbRiDXgIhvlDECSGkAzXdhGHSnU6GD4o4IYSEIKVEtWHAlIBumNDSLOohwwPPRkIICaFhSCgjvEy3OhkyKOKEEBJCVW8Kd6VOESfDBUWcEEJCcCe1rdT0Aa6EkHYo4oQQEkKtYTpfl4fUEjdMiQ9+/UmU69xkbDQo4oQQEkISLPEHTs7jf9z6OL7+vZlBL2VdYpoSX3z4DOQQNvyhiBNCSAhVtyU+pIltcyt1AEClMZybjKRz17ELeMs/3It7j88NeiltUMQJISSEmiuxrVwbThG/oES8bnZ4JlkNKqFxsTp8mySKOCGEhOC2xFeGNOY8V1aW+HBuMoaRhXIDL/mz2/G1753v+Ny6YZ0DtSE8vhRxQggJwR0TLw9pTPzCSgMA28N2w+cePI0jMyu483DnPALdnmA3jJskijghhITgrhOPGhP/2J1H8XMfvSuuJbXhxMSHNHt+GPnMfacAAIfOLnV8bsO2xIcxXEERJ4SQEFoS2yLGxB86tYi7jl6Ia0ltXKA7vSuOzazgnqfmoKUEDp9f7vh8R8SH8PhSxAkhJISWErOIMfGabqBcN5ybf9woS3wjutOPzax0XR9/+xPnAAA/eu1OnJyr4JHTC/jNf34g8Pjpdt/dYTy+FHFCCAlB3bgLmXRkd3VNt8R7qU/ZzBvVEv/4d47jpf/na/jh996JU/OVyL93oWzlEHzfgc2QEvi9f30Y/3LPSXz5sbO+z2+604fv+FLECSEkBCXIU6UsVroU8YVKI7Z1udmIlvjdxy7gnZ95CNftncSZ+Sre8n/vify7S9UGRnIaLt06CgC49/g8AOCz95/2fX6DiW2EEJJMag0DQgDjhUzk7PS6nQy32AcRN0yJeft9htFSjItD56xY9rtfew1ee8NuPBkhtq1YquoYzWvYt6mIdEoAAPZNF3H7E+ewUG7/mylLfBg3SRRxQggJoaqbyGkpjOS0LmLi1k1/sRq/iC9UGlDdQIfRUowL1eBmupTFZCmLct2ILLJL1QZG8xpyWhp7p4rIain8zx+9Gg1D4kuPPt32fH2IE9u0QS+AEEKGmWrDQD6TRiGbxrwde+6EGprSD3e6EjMAqDSGrwQqLmaWayhl08hn0pgqZQFYTW+2jxc6/q5liWcAWMltK3UDz7loClpK4NjMStvz68bwJrZRxAkhJIRqw0BeS6OUS+PUfNSYuHKnx5/Yprq1FbNpVDeQO/3CSh1TI5Z4Txat/2eXo4v4tP27b3vJAefxyVLWOZ5udCa2EUJIMqk2TOQzKRSzWuSYeD/d6SqpbcdEYSjdvXFxYaWO6VIOAFos8ShY7vRM2+OTxUyLZ0OhSsyG8fhSxAkhJATlTi9l011np/cjsU0J10YT8ZnlOqZt8Z4qWYLsJ8B+qMQ2L5PFLOZW2v9mdV3FxIcvXEERJ4SQEGq6iVwmjUJWi14nbotpf2Li1nvsGM9vMHd6zXGJK3f63BpFfCrInW7a2elDeHwp4oQQEoIVE0+hlE2jbpiOVRZG053en5h4VkthspRt6fO+npFSWjFx250+XshAiGYTlzCqDQN1w8SYnzs9QMQbup3YNoTHN1YRF0K8QgjxhBDisBDiHQHPeZEQ4n4hxCNCiK/FuZ6NQl038c7PPISnF6qDXgohiadqW+LFnGW5dbLGpZR9dacvVXWM5TUUM2k0DNm3Vq+DZKmmo2FIx52upVMYL2QiWeKqi96Yrzs9g7lyA6YdA1c0zA2Y2CaESAN4L4BXAjgI4CeFEAc9z5kA8D4APySlvBLAT8S1ntVw6OwSfvz938Sjpxe7+r1yXcfsci2mVXXm6MwKPv6d4/jmk51H7BEyCBqGif/0N99KxDlasy3xQiYNoHNyU90lov1wpy/XdIzkNBSy1vqGsQyq18wu2zXitjsdAKaKWaf9bBhLdrKhf2JbFoYp29rlbtRRpDcCOCylPCKlrAP4BICbPc95PYBPSymPA4CU8lyM6+mKExfK+KkPfQd3PzWHh08vdPW77/6P7+GnPvSdmFbWGXURR3H7ETIIFisN3HX0Au4/MT/opXSkWSdu3S473chrruuuH9npKzUdI3kN+YibjPXAhRXLSFJZ6YDtCu/CEg+KiQPtWe4btWPbTgAnXN+ftB9zcymASSHE7UKIe4QQPxvjerri7755DOeWrBOl2z/cuaUaZgZoiauLuL4B3GokmdSdm+Lwn6OqxExZ4p3uB6rRixD9qRNfruooZbXm+oZw5nWvUZb4ppGc89hUKRspO70p4v4xcQBtFr3qnT6M4Yo4RVz4PCY932sArgPwagAvB/B7QohL215IiDcLIe4WQtx9/vz53q/UhwdPLeDybVZz/G7jIHXdbNmN95sKLXEy5Cihq3WxQX7L/70HH7njaFxLCqSqW5Z4LqKlqxq9TBWzWKw0IKX3ttdblmpWprVyp28ES3zWFmu3JT5V9E9K89J0p/uXmAHtWe5u4R42azxOET8JYLfr+10AvCNiTgL4opRyRUo5A+DrAJ7pfSEp5QellNdLKa/fvHlzbAtWmKbEo6cXcf2+SQBAeRUiPkgBrdESJ0NOvUv3pGlK3Pb42YHE0GsN03KnO5ZuNHf65tEc6kb8G/qVmo5STkM+E83dvx644CPilju986Yp1J2uRNyT5a5KzIDW4/utJ2fxmftO4tzS4JKI4xTx7wI4IITYL4TIAngdgFs8z/ksgO8TQmhCiCKAZwN4LMY1ReLo7AqWazqu3jWBnJbqeuelLty4d+BB0BInw06zeUa0a+vcUg0NQ+Lpxf7eLKWUliXeRWKb8jJsHrVcvXFnqKvENicmPoQZ1L1mdrne8pkBq+FL3TA7NuRZDEtss5vGtFnievNeXnOFgP7Lpx7Ar/+/B/B9f/JV3PrQme4/SA+ITcSllDqAtwH4Eixh/qSU8hEhxFuEEG+xn/MYgC8CeBDAXQA+JKV8OK41ReXhU1Yi2zN2jqOQTXe9s1U3KBVH6TcqzkgRJ8OKcjlHjYmfmi8DQN/LJuuGCSmBXCbtCEanNavP5oh4zMlty3ZiW9SY/XpgdqXWYoUD0Ru+KEt8JNduiY/kNGTSoj0mHmCJzy7X8apnbMNVO8fxS/94L7577EJ3H6QHxFonLqW8VUp5qZTyYinlH9uPfUBK+QHXc/5USnlQSnmVlPI9ca4nKg+dXEBOS+HAlhEUMunuY+K2q3BQ7my13mFLwCBEoVzMUQXn5FwFgNVqs5+bUyXYuW5KzPRWSzzOMjMVuhvJbqyY+EqtveOaEvXZCCI+ktOcOeJuhBCYKLZnueuGhLCfru6vNd1AuW7g4PYxvP+nrwUAPHamu3LkXsCObT48dGoBV2wfg5a2LtzVWuKDsoTpTifDTrfu9FPzFefrs310qav8knwmjXyXJWaqEUm3OTXdsGIPZNlolnilYTifV7F1LA8AOOM6V/xQs8SD8EuQaximY7mrv/+8HTefKGYxXcpBCGuT2W8o4j6cmq9g/6YSAKCQTXcfEx+wiDOxjQw7SuhqUd3pc4MRcWWJ513u9E4Z9eqzqbaeUT/jaliuNV3DUT0F64GqnWzoZu90EQBwbLYc+rtBfdMVk6VM2xCUhqtNqzq+Sugni1mkUwJTxexAmnxFFnEhRCnOhQwTlbqBou2aWpUlbgyHJT7IMjdCwlDXRtRe1CfnKo5IdZPcJqXEmYVwyywMtT53nXin8JqKiY8VMi2vEQfu+G4+u3ES2yp1o03ER/MZbBrJ4qnZldDfXar5jyFVTPpa4tIRflWdoIR+smi91vRI1qlf7ycdRVwI8TwhxKOws8aFEM8UQrwv9pUNkHK96aopZFcRE1eWuDGYi0mJ+KAS6wjphONOj3htnZqv4JrdEwC6S2774y88huf/r6+sOuFIeeHyWhqZdApaSkTOTu+HJb5S35judKuLXrt87Zkq4qk1WuKlnOaEKRS6yxJXm7J5W+gn7IS66VIOsyvDaYm/G1YjllkAkFI+AOCFcS5qkJimRKXRtMTzmXTXM2RVQtmgLOFmdvr6v5hJMql1YYlLKXFqroIrto+hkEk7Im6aEnpIyOjzD57Gh+44ClMCf/qlJ1ZV8qnWqay+QiYdITvdFvGC1vJ9HCzblngppyGTTiEdYZOxHqj6xMQBYN90qaMlrurqgxjJaU6YQtEwm5Z4xe6Ip2rJVVna1LBa4gAgpTzheWjdniXqplLIWn8wKzu9u9aJTryPiW2E+FLvosRsrtxApWFg12QB28bzOLNYxb89dAY3/o/bcP0ffxl/9LlH28T80Nkl/Jd/eRDX7Z3Ef331Fbjr6AXc/kT33R6VVZuzrb5chPCa405XlniMm2klNqM59/1q/V/3lYbhZOO72TtdwpnFaqg3YqVmoOTzu4pSLo2VutGy6WsYZlPEfWLiALCplB1Iu+3g7UiTE0KI5wGQdtOWX8EQNGSJC+XeW1NMnIlthITidGyL4E5XSW07JwvYNpbH1544jy88eAZX7RzDvukSPnLnUdR0Ay87uBW7JgrYPVXEW/7hHhSzabz39ddispTBx+86jrd/8n589q0vwB47ASoKTmKbpsJrnZs/NS3xTMv3cbDsyk4HlOdw3dpYDpVGe0wcAPZtKkJK4ORcGZdsGfX93ZV6uCVeymkwTGucrHoP3ZDNHIdG052ez6Sc50yP5LBY1VHXTWS1/uWMR3mntwB4K6zhJScBXGN/vy5R5SBql9dtTFxKOTSJbe4uQ4QMEypOHMWdrpqlTBQy2Daex3JNx7P2TOAzv/R8/PXrr8WbX3gR/vE7x/HGj34Xr/3gt/FHn38UT55fwbtfew22jeeR09L48BtugCmB3/yXB7papxMTty3xKH0j1GdTllus2ekudzoQbZORdKSUvtnpgGWJA8CxGf+4uJQS5bqBUjZExO2fuV3qdcNEIZu2whUqsa3ccKxwoDkWNcoQll4SaonbM8HfI6X8qT6tZ+AoAXTHxLuZtKSbEsoLMzARV80IaImTIUVtdBuGFdfW0sH2RFNI0ziwdQSjeQ1/8dpnIWP/zm+/4nJcvLmEfCaNd3zqIXz8O8fxw9fswPcdaM5Z2L+phB+7dhf+6a7jkFJCCL/5TOHvrf7vtPGo6QYyaYFMOoVsOtUXd7oSnrzWfSJu0lCeDb+Y+N4pVWbmHxev6SYMU6KYC3OnW8dypaY7U9J0w0TW0zdkvlx3ktoAK7ENAGaWa9g2nu/2Y62aUBGXUhpCiM1CiKw9E3zdU/Zxp9cNs+ONRuEW7kG5s9l2lQw7bhdzVTcxEirizeSyX3zhxfjp5+x14s0AkE4JvPaGPc73H/z6Ebzz1Ve0vc7e6SIqDQPnl2vYMhrtJlu116li4vkolrhuIme7363ZC/G604u2hajWt97DaOr4+2WnTxQzGM1rOHHB3xJfqQW3XFWM2AKvNkiGKWFKQEulMJLTnCYvliXePA83jUTrGNdrosTEjwG4UwhxCwBneyOl/D9xLWqQlO0ktkLGOjRKzDvdaBQtIj6w7HSV2La+d+QkubivjWrDCL2pKsunkLHEaiykxvfma3bi5mt2+v5sj22lHZ8tRxbxmscSL2TSTmlR4O/ohhMTzWXitcRX7OEnipzWu/f7/IOncdnWURzY6h9bHhRO8rGPJS6EwHghg6WafzLySk0ZaeExcfdzVbWRlhbYt6mIIzPLAKwe7VdsH3N+b9q22vvd8CVKTPw0gM/bzx11/VuXeBPbum2g4O5XPvCYOOvEyZBS84h4GN649GpRCW2d6ojdOCVmmnKnd7asaw0TOSXiWjrWxLYle/iJIhdhfVH4268fwds+fh8+PID57Z2oePKWvITlLTh19RHd6YAVIgWAbDqFS7aM4PC5ZUgpMVeuO+VlQDMm3u8ys46WuJTyDwFACDFqfSuXY1/VAPFzpwPRGyi4L9g4d+BhVBNQYvav953C7U+cw3te96xBL4UMAPe1EVXEcz6WVzfsmixACOB4gKtVN0ys1AyMu1yk1YYBIYBM2nJXR6lWsdzpSsRTsdeJt1ri6TUPXHni6SX88a1WAVKnsZ6DQB1/FbLwUsymA/vVK09rmCWujqdypzf0piV+yeYRLFV1nF2sYaHSmtg2mtOQTacw0+eGL1E6tl0lhLgPwMMAHhFC3COEuDL+pQ0G7y6v237E7njUwOvEhzg29uE7juJf7z+97jNpiT+t7vRozVPWaonntDR2jBcCRfyD3ziCF//57S1WXLVhIK+lnUS4KKOJa7rhCExWS3Xstb4WfN3pa7TE3W1thzFJTp0vQZZ4WJndsu0iL3VhiasxpJl0yilbu+/4HEyJlsQ2IcRAWq9GuSo+CODtUsq9Usq9AH4DwN/Gu6zB0YyJN+tCrccjiviAE9tU+YV3LcPEmYUKHrJntgcloJD1jTcmHoayhrMRclI6sXuqENjR68SFCi6s1PHVJ8653tts2TzkM+mOte013WxpDhN3nbi75jnfg/dTfxsrKW8YRTw4Jg5YlnjQ5qNcay3J82PEttKVF0KFJTNpgUu2jAAAvntsDgBaEtus77N9LzGLclWUpJRfVd9IKW8HsG6HoZSdErNm8wQg+o500Ilt6gIWYngt8dsea94kO00cIusTt9B0smy91vBa2DtVwvEL/gNRlux69M8/eLr1vV1iEanErNHqTo9TCJdrutOtTb3fWsN46r41XsgMZeOYsOx0wLp3B61bCXNonbhtpTsxcaNpiW8dy2Ekp+HWh84AQFspWdgGIi6iiPgRIcTvCSH22f/+K4Dhy3boEZW6tet3N3cAosfE6wNObFMn0EhOQ103V9UvOk7OLFTw2ftPOfWXnfock/VJXTdd11b4deK1htfCnukiZpZrbQMugOZEsNseO+fEQ6t6a1ORQiaNhiFbEli91I1miVkvLOMwqg3DSb4FehODV5uA8UJmON3pIdnpQHgZ4EoES1xLp5DTUk13um2Ja+kUhBC4eMsInl6s4upd43jO/um2945zap0fUa6MNwHYDODT9r9NAN4Y56IGScWeYOaOgQFdxMQHbIlXXRcgMFwZ6g+fWrAnSs3hjc/fh7G81lWmMFk/1A3TGRASxZ3u151rNagysxNz7efdUrWBYtYS3buOzjrvnXO10Iyyqbdi4qtLbDtyfjl0g9D+XmZLmCGXSa/Z8ndb4sPoTm9a4mGJbQElZk5iW/j55B6Cov4eGbsW/5LNlkv9na+6AqlUq3eo2+ZgvaCjiEsp56SUvyKlvNb+92tSyrl+LG4QlF0TzABEniGsaLHEB+DOVutUtbTD5FJ/arYMUwIf+bnr8Usvuhj7NpUCOyuR9U1NN5yNZkd3uu7fYnM1qGzixUr7TX6xqmPHRAFAMwem5nlv5REIu1HXGq6YeBfu7eWajle85xv4zL2nIj0fsATXvclQm4a1eODUPWOimImcC6QwTIlDZ5dW/d5R8HbR8xKWfLhS05FOiZZj5od7HKnuxMSt33nTC/bhv//wVXjORdNtv5fPxJvI6EeU7PT/EEJMuL6fFEJ8KdZVDZBKvXU6TtfZ6QO2xNU6lZXTGKLkNlX6csX2MQghsHe6REt8g1LXTUfEO930vNbwWlDtNld8LLWlagNTJUvklfXlnVudj2SJuzu2pSNni5drOuqGiTM+89KllHj86cW2x+pG67CNnJaClGvzwKn71tgqYuL//sjTePl7vo5zi9FnvndLp+x0NS7WNNuPgZpg1im/opTTnEz2uqvZCwBcuWMcP/2cvb6/l++BJ6RbolwZm6SU8+ob2wrfEtuKBky5rqOYacZL1IkSOSbeUic+AHd6o+kKA4bLElcirta2d6qIU/OVrtyHZH1Q103HW9Q5Jt47d/qIp3zIzVJVx7Qj4pYA1BpGSz1ylPBaizs9E92drq7V5Vp7nfd/PHoWr3jPN3DkfLNNh5rTkEm3bzLWktxWW0Ni28xyDaYEzi3FVyut1pQP2Ng1u2y2r73cYYKZopRNtyW2RamOyGdSTqvefhFFxE0hhNOYWAixF8DwBFp7TNljia82Oz2TFoOJiTc87vQhssQXqw1oKeF4N/ZOF2GY0hk1STYONd10RjtGyU4PSmLqFnWDL9da31M3TJTrho8l7ikx06Ja4t2709XGQSXYufnO0QsAWidkqTV6LXG1htXiWOL5DOr2wJCoqA2ZmjwXB5WGNWAmaJaFun/7hQJWakbHeDhgu9Pr7YltnRjEAJoovdN/F8AdQoiv2d+/EMCb41vSYKnUW//ImXQKmbToutnLaD4zEEvciYn3YZZxtyxUGhgvZBxXlhobePxCGfs2rduqReJDXTdRzKahpUSExDYTm0ai3Ko6U3JqgFuFUgmnY4nrzVGpLdnpEdowV+rN3+nGna5E2U/E7z8xb72261gpsW1JbIuwyeiESpZTpVbVhhHJenW/7+Iau8Z1eo8wz0xYHtNKXQ/t068YyWlO8mOz2UvnEkeVnd7NpLy1EqXt6heFENcCeI790K9LKWfiXdbgKNcNTHgK+POZ4DZ+XtSFNZLTBuLKbs9OHx4RX7RFXDFl9x1ea5tIkjzquhXLjZLN20t3uhIj7/WshHPSFnHVL1vVqCvyHXJkqg2jxcuQ01KoG1Z81pvJ7EXdO7zDO+q66TRHch8rR8TdlnimN5Z4Vku15ANFFnFdibh/dngv6CjiISGPcs0IbbmqKOXSgYltYeQzVk6Cu8wwbgJXJYTYK4QYBwBbtFcAfD+AnxVCZIN+L+lUfE6QQhfJCi0iPoDe6Wr36cTEh8wSH3OJ+Kjt8o/T9UaGE5X8FdYiU+G1htdCVrM8a8seoVTnoHKn14Pc6U52uv+a1euM5VubRUXZ0Dct8dbr4bEzi8517D5WNT8RV+70NZQ51Q3D2WAB3bVe7Ys7vR4eXimGuNO9He6CsLLTW6eYRRPxaL0PeknYqj4JuzObEOIaAP8M4DiAZwJ4X+wrGxDlut4WM4nSL1mhLtaRvDbYmLidnT5MiW2LHhFXcfs4d+1k+HBnVUcpyellsxfA6uhVrgW5060mRMr68lp9nRrUqHPZbYkD0UQ1KCZ+3/FmRa+75WvdJ+FKWX9rSWyr2+70bpN63c+N151uhop42ObDSmzrvCEcsWPiUsqWUaSdUEN6+llmFnZlFKSUqv/gTwP4iJTyz2E1erkx9pUNiHK93d0SNtrOixLuUjY9GHd6o5mU4l7PIPmDWx7BN5+cwWJVb3Gn5zMpaCnRZnmQ9Y26LnLKnd5BcKqeDPG1Usqm26ZzKctxophBSljWl5TS7oMePTtdhYYcEXfc253vH4473XM9PHRqsekBcL1OnIltuUzTnd5NrXjTEo9vY17xlP15UffvSqN9DcuR3ekapLQ+u9M7PRUlsa1zH4FeE/Zp3NuOlwD4HQCQUpr9CtgPgmrDaKs/jOLyU9QNE5m06CqhpZc068SHo8RMSomPffMYGoZpJ7Y1TzkhBMYKGbrTNxhKYHK2Jd5pg1xr9K7ZC2DdoL0dvZT1O5rXoKWtOLZ7nYpOwqbO5XHHEleWcXR3+rJHABcqdewYL+DIzErLsfJNbMtEf78g6oZtiXfZIwNwx8TjzU4POx/C3Onluh46S1zhnmTm9E7XoiW2Af7lbXERJuJfEUJ8EsAZAJMAvgIAQojtAPo7pqVPNAwTDUOi6DlBsloqskWrXFFZO6Gl39R1EynRvNkM2hJXN5NT8xUnO93NaF7zzcYl6xd3QlahQ2KbYVqu9566013xTsWSE8vOIJtOQTekswl3C4aTxxEgUupx5QlrWsYRLHH7frFSN2CYEmk7Ea7SaCbb+man+1jia8lOd5IOu2w5DTTdyHFuzGsNw0lA9CMoO900pa+n1Q8l9Ms1HQ07yVGLYol3OWujF4St6tdg9Uo/BuAFUkr1V9kGq+xs3aF2bl5LvJv+x+oCyHUh/L2kYZjI2A381XoGiTpuh84uwzClc3NTjOUzse7ayfDhtiA7ebmU+PXUEnc18lCojeRIXoOWFmgYpmNNuTcQ6ZTAWF4LrKhwRNz2OOW6cK+6K0nc1nilbmWHZ7VUx+z0fA+y02v2PcxpmrIKd3qcFScVT8WAl6CQh5pQGa3EzLpPLdd0p9wwarMXYEgS26TFJ6SU75ZSnnI9fp+Ucl22XVU7N+9OLaelu7PEtVRX1nsvaRjSrm0fFhG3jumpeauhi9cSHyvQEt9oOG7qTAqlrObbPU2hboZB3blWQzGrtcXEl6oNFDJp59ppGLLZo9sjGBPFLObL/s5IFQt2LPEuOqi5RXzJ1bWt0rAy+b1VMnWfrGnHfd/BEjRNid/65wfw3WMX2n6m6sRX5U53EtvijYkHtVwFgi1xlcxYjJjYBlibKd2Mntg2bJb4hqMcMOGmm65LKut2cCJuxeTV7nzQdeLevIA2d3qOMfGNRtMST2O8Q06E02Kzh5b4SK59ytViRceoXRaWTacsS9zHnQ5YyW/zAZbmQqXhJOwBzc1HpOx0vdkZzb2xVXk63vyBuk/MPmpi24m5Mv75npO4/YlzbT/zqxOPihMTj/GarnbIkQjKW4gyS1yhzoXFqt5MbIvYsc1aI0V8IKg/uvcE6dqdbsfEawMQUN00odnvDww+sc37/mM+ljhLzDYWbjdwp79/p4lVq8E3Jl5rlj9qaQHdMF3v3XqbHC9kMF8Odqe7N6rdJJq5r5Uljzu9YGeLuxOm6r7Z6dHe79HTi/Z624+9moyWj9CdzouTnR5niVk9PDs9lRLWhsfrTrc3bmFWvEJ5UpZruqtOPIolrqoIhsCdrhBCvEYIsSHEXvUI9v6xcpkuEttUTDpt/c5aRgKuhoYhnU0EMATu9E6WeD7DErMNhvJq5bQUxvLWkI2g8zQOEQ+KiSvrS7nTlRC2W+LZwJivt6FRN4ltLTFxlzu9qlvNTfKeUlf/7PRo7/eILeJ+157qNtbtGGag+fdaqRtOVnevqUTope9XFtwMl0Zwp9vnwlK1gYZhIp0SkdqoDqs7/XUADgkh/rcQ4oq4FzRIlNymPH+sbLo7SzynpVzu7H6LuAktLZwLe9C90703k7aYeD4T6wVPho9WSzy8a1/Tpd3bmHilYbQM9lis6k7muZYSqLssce8Y1IlCJiQm7rHEu6jbboRY4vlse3e78Oz0Dpb4GdsS98lHUe70TNrq4xDmTj98bhnv+vyjzthP9/vGkeuiGyZ0U3bc1BWzWps73UlcjrAhHHVEXIduyEhWOOCaIjdMIi6l/GkAzwLwJICPCiG+JYR4sxBiNPbV9RlTWc2ev1cuk44eE3cltgFr65y0GnRDQks1RXzgMXG9szsdQFsbTLJ+qbncwErwgtyvtVhi4qoZSPPaXKo0nFapWS3lcae3x8QXKg3fedULrtcB3B28ondsA5riapqWR6CQsSxj9+v4NXsRwsqH6XTfeTTMErdDgoBt0YYI0hcfPoMP33EUM8vW6NGaqxwujgx1d6OgMPKZVJs1rD5HFHd6Jm31MLAscRmp0Yt6X2BIstPdSCkXAXwKwCcAbAfwIwDuFUL8coxr6zvK9e21xFVMPIprXCW2qdhUv93Zyp2fSgnLohi4Jd58fyGAUU95xyhbr244lBDl7Jg4ENzhqxpDiZnKTna3Xl2qtbvTq7q/F2C8kIEp2weVANZ57GeJR2n+4b5WVYmZ+r1CJt3W/lldW96Eq5yWCt00zC7X8PRi1Vmvl5puOBuDQjZ8bsR5e2642oRXdQNbRq3WtXEkt9UDPrMXyxJv/WyVLixxwCozUzHxTMTqiKF0pwshflAI8RlYzV4yAG6UUr4SVg/134x5fX1FabR32FBOsybT6BHm6roT24D+J5bptogD3TWpiQtlSY3mNYzmtLZJTmNOFijj4hsFtzU11qF5ShzudJWd7Pb+lGu687iWsuvEHXd6e0wcABZ8ktsWqwEx8Yh14pm0QNrVirji6l3hTdYKskpzWjrUff/YmSUAwI7xfLAl7hLx5ZqBv/vmMd/Y+PnlpogbpkTDkNgymgcQz8bcKavrIKoFn8mT5YAS4iDG8hoW7RIzrcMEOkUmnUI6JYamY5viJwC8W0r5dfeDUsqyEOJN8SxrMJiON90TE3fFtTrtAB13+oDqtHVTOvWMg+oaBwB/+qXHcXKugpddsRUAcN3eScz53PQ4yWzj4S4xGytYjwXHxP1rtdeCty2naUqUGwaKuaY7faWmB7ryJ2yRnq/UsQdF53HTlNaQn7xbxKPXiSsDIKOlnHiyu8Qu760TD2hC0qkk9vGnLVf6jfun8OXHfErMDJeIZ9K4/Ylz+NwDp7FtPI+XX7mt5bluS1ytLU5LXIUcsh1i1IVsui1voRt3OtDsJpkWIlIynCLvacoTN1Hmif9syM9u6+1yBkvTnd76uLuBQqduP9YFkB5YdnjdtdHI2PWug+CxM0s4OrOCFx7YDAD4vdccxM6JQtvzHHcq3ekbBic7PZNysqmD4qdBtdprYcTVFxuwXMBSWlnrgLLEZaAXQMV8vWVmK3UdpmxN3sykBVIiemJbRkthJKc13dMuEfc2e2kYloXo9W7lM+GJuIfOLmPTSBZ7p0uOBa1avJq2Na02BvlM2tlQ+DXlcUS82hTxzWO2iMcQE2/4JPP5UcymcXrem51ul5hFdafnNSxXG2joJjbbG5MoeDdbcROoSEKIJTQTtgEr3Uuq/6WUYzGvre843nIfdzoQzTVuiahosd77iZW5abvTu8iq7zUNw0SlbjjvX8pqvjdiZbWwzGzj4G27CgRv4oJqtdeCsriVJb7sdPJyx8TNwJavjoh7RGrB03IVsBLNOrm3FXW726K77LJSt34vqMTMT8ys4UvBInLo3BIu2TLi5AAsV3WMF1sHJrktcYW3yx3QFPGVuu7kECh3ehyJbVFne/sl5JXrhpX0GzG+PZrL4NxiDUvQccmWkchrzHeYB9Brwtqujkopx1z/Rt3/922FfUTCP7Et20Vcy6qxHFxMvOGKiQ+qfztgZcmX63pLTbAfTkyUrVc3DDWXNZXPpJBJi2B3eky904GmeJdrqqe29XhGa3ZsSwm0xUPHCyom3uquVRsRbxllLsLMdMC6drPpFEbtWCzgcgErS9yVYFsPCO/lQixxKSUOnVvGgS2jvuV93ji72/XsncG+UtMdYXdb4tOlLFIinhKzoGQ+L4WsT514h3atXpQ7/fxyrStLPOeTGR8n0SL8AIQQWwDk1fdSyuOxrGiABFSYdTVOUMW1cunowt9LGoZ0pu0MMrFNN01UGk1LPBdgSammChyCsnFwtwsVQoQOwVHDNzqVFHVD0xK33cROu2XbEk8J6KbVOz2fSbc1+VAi7XWnL3gmmClyWnv3MD9UYttoTsPpBSt7vBnHTaGQTTvJY1lNtMSuve8XdN85t1TDUlXHga0jvkml3laubkvcmyimysoAa0632/U/ktNi8a45ZXURLHHveq3Od9FFfCSvYa5cR003sXmkC3e61l93epTs9B8SQhwCcBTA12BNNfu3mNc1EJzs9FR7iRkQLb7trRNXzfP7hW7fCIDBJrY1DOtmo+JoQRddOiXsC56W+EZBjcvV7HPC6p8eVGJmOmLfK0ayKiZu3WjLnp7amXQKDd2aYubnAchqKZSy6RB3equIl3waj/ihvGijec3p2FZxtYJW9yEl7GpQiRfLfe//fofOLgMALtky4gplNY99zRNzbrHEPSVbypUOWB3m3DkEo/mMbwneWnES2zplp2fTdq5DMyJsjSHtxhLPOMeju5h4qq/Z6VG2t+8C8BwA35NS7gfwUgB3xrqqAaGavXhvF1Ebt9x7fA6VhoG906WBTRHzutP77QlQqM3LfLkBLSWcG7YfVikHLfGNgrsOGQBGC5mQxDZ/IV0LBSc73RKZZc90Ky2dQsO0EtuCpqdZk8xa13xhxXKvT4+0zrou5tqtQj/qujsmbq2p5qkTB5plmw1D+noowmY9HDpnlZcd2DLqOxvd2wVOWa7plHBc5w3DxO9/9mHcd3ze+b0VjyWuXNG9JmpMPJ9JQ8rWcKblTo/sfG5p2tN9YtsQZacDaEgpZ4UQKSFESkr5VSHEn8S+sgHgiLhPsxegszv9w3ccxWhew488ayeOXygD6H/HtIbRLDHLae3TmvqFbu+Y58r1jq5Q9k/fWFitiZvCPJbXAt3pQclba0GVgC4rS7zWaoln08068aANxHghg4VKa0x81nYvT5VaRbyU1SJ1JFTZ6UoApZStdeJa61SxumczpMhnghPpDp1bxkQxg00jWefe4BZbd/kfYFnsF28uoW4nqgKWNf/333rKCSvk7JK4dhGPs9lLuGfGabpSb55rapBMVNyVSN2KeJzz1L1E+UTzQogRAF8H8I9CiL8AsC59n83e6a2PR5kJfHq+gi8+/DR+8sY9KOU0Z6fY/+x001UeMtjsdMAezdjBkuIks42FN5Y7FjKOtG74u4zXiltkVEy85LbEdSuxLejcnShmHMtbMbtSx2hOa2sOU8q1dw/zw0psExjJazBsT0BLYlvWK+IBiW1acGLV8dky9k2XIITw7dHgtcTf8Lx9+PLbb2qZ+z67Ym1WFioNpFMCuyYLWKnpjvVZyKRbvAm9xG+Guh/Kg+B2a5freuRGL0CzhwUAbOomJt7nxLYoV8fNACoAfh3AF2H1UP/BOBc1KGQHSzzMNX7PU3MwTImbr9kBAK7e5f2fYua2xPt5MnnXAVju9EiWeI2W+Eah1mgVZiuxzf+Grxuy55Y4AIy7ZoKrrOuWmLgpUdODR17unS7hyfMrLTHX2ZV6mysdsETcO/rUj2ZMvFl2WfHUiQPN2vnAxLaQzfuSa0CLe8iHom5Y7+ftx17MNkMC7oS2qVIWY4VMS7MXKyYezfvQLX794v1Qfzd3hnqlYXadna7w+7sGvrc2JCVmCinlipTSAFAE8DkA/4DW+vF1Q1Db1Sg13+qEnbRbMg6q2YvVAMIVEx9YiZn1vlHc6ZY7lZb4RqFmmC3VCuMhlnjDlajZS8YLzYx4FetVMXHlTq81zMBz98odY1ioNJwscgC4sFJrc6UD/qNP/VB14s2scR3VugEhrGs55xGmhi6DE9sCNu9LNd2pCMmkrRnl7lCGk9jmeV23N2FmqemB2DySc5rTuMsB446JR8lOB1qH3FTqelfZ6UrEJ4qZNu9KGN0MzOoFUbLTf1EIcRbAgwDuBnCP/f+6I6jtapT+x+oiLTkNI6zX6H9MvLk7z4XExmJfh30wF8qNjrvmMHcqWX/UPVnVYwUNdd309Rq5EzV7iTVO1Bbxmt4y+U9LW7MSVup6YEz84A6rVcYjpxacx2aX65j2cbsWXa7oMBp2/F/FYpdrOioNA3nNKnNrWuJ2dnpYiVmgJa63DCEaK2i+2eneklB3ydbMcg3ZdArX753ERZtLTRFX2elaGiM5K88lytCobmjo1ut16p3uN4ik++x06zh1U15mvXd/265GuTp+E8CVUsp9UsqLpJT7pZQXxb2wQdB0p7c+7tSJhwiyssRHXP2Xgf6LuBpFCoTHxuJfh/W5l2p6x12sO5GHrH9qemusOWwIirJOe81EMYt5OzFN3dxVGE2931JVD+zZfvm2UQjRnMsN2O50H0t8JJdGuWH4ji51o+L/Xne6cgGr/6uumHhQxzbdlM416Ga5qre4iUfzGf+YuI8lrnIHZpbr2DSSxcfedCP+9MefiZGcZsfEm+10R/MaGobsuRFRM7pLbGuxxLusdFB/h26S2gC0tceNmyhXx5MAynEvZBhwLPEgd3rIH2alZrlqVA/iQSS2SSntASjKEh+kO715w+rsTs/AMGWkMhySfOq64TRDAuDbOUzR0ONzp7stcXcmsnq/5ZoeGBMvZjVctKmER+y53KYpcSEgJl7MaZCy8zhSp9mLK1ZdqZuOBe6bne6zwVFr9vaI0A0rUW4k10zYGvO4vb3NXpqft9kBbWa5hk2jlhu9kE2jlNOwXLUGxijXf1zTCRsBmwwvzXI8V4nZai3xLkU8nwneRMVBlFS93wHwTSHEdwA4GQ1Syl+JbVUDI3ieONApJm44rnTAndjWPxH1TvjJa2nU7TaNvWyWEWktriY3Qd3aFKOuphOlDgNmSPKp62ZLlrBy7/rFUBsBLuO1Ml6wsqfV5rHYIuLKEm+EWm4Hd4zj3qfmAFiZ2oYpMVVqv+GXXO7xsOzohp1t7rjT7bItJcpt2ekh7nTASoAruvYUKrluxGOJz7nax3qz0xXFbNr5/ZnlmjOpzHoNDct1y/WvGvOoa3q5qmPLaOBH7pquE9tcXgvdlF2JeCFjDbLaOpbv/GSf967qJkZi8CJ5iXLH/BtYs8QfAjDY4dQxE2SJR8lOX67pTu9lwOr6pqVEXxPbVIMVtyUOWJuPXjfM6LiWFku8c4kZYO3at413d8GQ5FHTTUwWXc1e8k2R89IwzFg2dmqIyWKlgeWa7vRTB5oi3jBk6HVz5Y4xfO6B01goNzBrl5tt8stOV81lagYQImh1QyLjnrHucafnPdnpgYltASWxyip2u9PHChmnp4W1hiAR11CxQwKzy3Uc3N4cn1GyPQ1z5eamxy/zvRd0MwAFaIYe3Fn+URFC4MNvuB6Xbu1uF3Ld3kn8yksPIN0nwynK1aFLKd8e+0qGAFP6W+JCiI4TwVZq7VZkv0eBOkkfTse2pkupnyKu3PqKKO50gP3TNwreWO5IyA2/EVtMvDmJzFs/rLnc92FepEs2W5Otjs6uOKE2v+x09dqdSq7UABT38ag2mv2+HQsvoiXuTcRV7+9ObBv1NNoJjonbG5GGgdkVy52uUJ6DmeWa4/IfCfGurAW1Pu9QGi/emLgKBXRTJw4A32ePUu6G6/ZO4bq9U13/3mqJcnV8VQjxZiHEdiHElPoX+8oGQFCJGaAyPoNjWss+Ip7VUn2tE1cubBXTyzuWeH9jzbongadznXg8F/x65quPn8PtT5wb9DJWhVd83O5jL5Y7PZ6YOADMl+tYqRmOSAGtAhaU2AYAu6YKAICTc+Vmy1Ufd7r6fJ1yPlRMPJ2y6rKd7PSMKn1LISWaghSW2Aa0h/+c5Fu3JW43ZXFPRgPaLXHVrvTMfAUNQ7Yk8KnPN7tcd+45ozGNGK7bs847hQcdEa+r/vhqyE1/PZL9IMq25PX2/7/jekwCWHcZ6qaTHd1+gnRKElup6djmiZ1k+jzPW7mwm3Xire63fq9D0dmdHpzYRNqRUuK//uvDqOkmvv07LwntSz+MeOuv/TqHKeIqMXPGidqWuHsDHtUS3zmhRLzi/L5/Ypt1/q906Nrm/qyqo1ylbjglTkIIa6Z4hI5tQPvmXQnqiMcSrxumE3JTv+MVcRUSUK73zQGWeFsjmR43fImaI5F3hRKB1bnTk0JHEbeHnmwo/C3xdGh828+dntP67E73lF8EXcyxr8Mzua3TRTfqam5BOvPUbBmn5isAgG8cnsGLL9sy4BV1R6Al7hsTb47W7SXKnb5QaWC5ZrS4WTMRLfHRfAYTxQxOzpWxecTawE8W/UrM1NS04PNbStkSOlBtS73923P2eGEpZaA7PZ/xt8SVp8vdTtS9gT45V3Yy9r3udHV8lIi725CWXCKuksD8JqT1gqjNf7xei6Y7fQOKuBAiA+D/A/BC+6HbAfyNlHLdmU1BA1AAS4i6yU4HLDHtZ2KbN+kj6GKOm3ZLnDHxXnLH4RkAlrXxqXtOJk/EddMZsAFYE7JK2bSvO70ekzt9wjUTvFz3JrY136+T5bZ7soiTcxWkhMBYXvMV1aI7sS0A74hN1Tuh0midgZ21RVw933eKmSd2rnBi4i3udHsDXdHxY+//FhYqVnMm7z1QfYanZttFXL1ew5B4/iXTANx5Dj0uMYvomVHNcdQxKG9kEQfwfgAZAO+zv/8Z+7FfiGtRg6JjTLxDnbg7Ox3of2KbikVrHku83w1fvPWRnUrM8pk0sukUY+IR+eaTM9gxnsfLDm7FJ757ouvBDoOmphtt58RIQJvOuNzpygKdK9cDS8wABNaJK3ZNFnDo3DK0lAisJy5FSGzzetFGchoWq7o1eSvrtsQtl7eTRR7mTm+YmC/XIYRwSurUayvUBvrcYtWZvOVneKicAWWJu8MGynjJZ1J44/Mtx63amPX6mq4FhBD8cIce1rM7PcrRuEFK+QYp5Vfsf28EcEPcCxsEQW1XAduNFSDIhilRabRb4tk+u9ObY/qavdOB/lvijbbEts4XzliBM8WjYJoS33xyFs+7ZBOu3jWBum629LIedkzTcht7xUe17vSix5Sdruqxn7Z7n/uVmAGdb/q7Jgs4OVfGXUcv4PqAjOSSk9gWRcSt9x6zx/NWPZUl6j4UlIBmPafpgfvlf7oPv/JP9wGwEgdTotUaVVb0sdnwfl5qk3j43DKy6VRL2GCikIEQwOtu2NNioY/kNV/vylpodDEQxz3Xe0O70wEYQoiLpZRPAoAQ4iIA67K1VlDbVcB2pwckiKmElRGfErO+JraZqsRMZad3HqEayzq8lniEi86aZEUR78SZxSrmyw08a8+Ec74lafMTVIfsbf/pfn4cIg5YGeoqt6DUYom73emdLPEiqg1rbOnzbFeyl6yWQiYtnPnlfnhHbI7mNZxfqqFumC0bDHUf8m7Y3bhzYc4t1nB0dgXVhmH3stBaXOXKI/HU7AoA4KqdY9g7XWp7zZIrJn7ljjGnMyUATJay+Kf//Bxcs3ui5XfimE7Y0KOPpnWPBC2vssQsCUT5RL8Fq8zsCKy07b0A3hjrqgaEDGj2Ali726CdtNptDtoS9+7mm7Gx/g9hcRNFxOOaerTeUBbFSE5z4plJOm7OgI02EW+3xK1kL9PpQNhrxgsZnHZEPMAS7+BF2jVZcL5+7kX+Im69fvhMcW999kiueT089+Lm66rhJmGdy9xNnioNA3XdxL3H56zhJ66kNsBtiVsi/oc/dBWu2zvZ9ppul/5l29qbnzzH57PHcU03DBOZiDkShWy6rdlLN1PMkkKU7PTbhBAHAFwGS8Qfl1LWOvxaIglq9gJYF898JcASr/lb4tl0KvTC7TXqwvaWmPU9O91p/2q5/nIRLhxOMotG1XUzclpbxjC3OS6CenO7XdsKw5SQErGV0E0UM7jvuCVeLc1eXNnwnfI5dk0WAQCXbBnBlpD2nKVs+Exxdc0ogVJ/221jeVy7pymqKrGtFuJOzztNngzHAv32k7NYqjba7lEqJq4S1vya1QCtm5wrto35PsfLaD7jxNl7RTeemYI7Jm7fh7uZJ54Uol4d1wG4CsAzAbxWCPGz8S1pcKhIrp+Ih7nTvRPMFJm06GuzF5UV3tbsZUB14spVR0u8d1RdCTpxZQDHSbA7vf3v7whbjCKubvLuGK87G75TPseuyQKEAJ5/cbAVDqje451j4iprX1nIr3rGdqRSreup6UZgZzXA5YHTTUe8vnVkFsu11glmal3plGiKuE+JHAB7HKr19eXbo7UhnSpmMLPUW3svqDbeD3diW7VhIiU6Tz9LIh2PhhDi/wL4MwAvgJXQdgOA62Ne10AwQ2LiYTN61Q576NzpTrOXwdSJK3dvlEQUxsSj4cxszqQT2elOVXh4xXEkl2nzKNQ9Gdu9ZvdkEemUwFtuuhg37Gtau90ktpVyGj74M9fjbS850PF5Yc1emjFu67Oq7O9XX7295XnqPqSOjd8GWQl7tWGg0jCQTgncf2Ie55ZqLd3aANjDSjTneWqOgZdUqjnP3M+d7sfl28dwar6ChXLvruuGYUYyCoDWxDZVb9/vQVD9IEpM/HoAB+UGGPbcKSYe5JZWN5+ST4lZf+vE/UvMBlUnPupY4p1dWKN5DQuVBkxTtlgeSabaoaylYZjQDdmVi6/5mqnQwSHDSpglvlyzpoqppKmoE6tWy6++7AB+/gX729zgWhclZgDw/Qe3dnxOKRfNEs/Yn/XlV27Dx3/h2W3x6WadeHBim5ZOQUsJLFV1mBJ43kVT+OaTszh8bhmX+wjwaF7DfLmByWI2VOSKWQ2FTNrpINcJNSTlkTMLeN7FmyL9Tie66aWfd9WJ1/To4p80onyqhwFsi3shw4CTnR7QdjVIkANj4iFlaXHQ8NSODk7EWy3xKBfPVTvHUdNNfPmxs7GurZ/8xicfwG/88wOBP//fX3wcr//Qt7t6TXeCTk6z6uv9cglWajpml4cvdSXIDaw2JG5rVY/ZnV7Mar5x7G6avUSllNVCe6e780jU+z7vknbhs4wJ0wmRBcXsc1rKGTF606WbHSvam9gGNOPiU6X2n7V8hlwal20bjWzNHtxhifij9sz1XhC1YxsAFFzZ6TXdWJc14kA0Ed8E4FEhxJeEELeof3EvbBA0Y+LtPwubYqZuPG3u9D5b4t5RpGpH3n93uh0Tz0ePib/6Gduxd7qIv/rKYawXp8/J+QqePLcc+PNT8xUcOb/S1Wt6rfvRgFrcP/ni43jDR+/q6rX7gZOd7m324jMEJerYyV6TSUV3p0elFFAHr4j6WVXnyE7Z1rlM2nFjTxQzeJ4ds/fGxN2P+bWMdfOOV1yOX//+S0Of42bTSA5bx3I9FfG1xMTXqyUexZ3+B3EvYlgwzeC2q2EDUIIT2/odE1cDUNyJMP2tVQdclrgdX4uSna6lU/ilF12M3/7UQ/j2kQstZTVJpa6bodm5dd3EYrXR4kLuRNUjgkEJgeeXak6y0jARbIm399qOOyYeRMZ1s8/36MZfzKZDLfGon1VNU3REPCAUk3dZ4vlMGjddthm3PX6u7R4FuC3xcBF/5TO2h/7cjyt3jOORXoq4Eb1OvNDiTjcihfWSSMejIaX8mvsfAB3Af4p/af0nzBLPaWkYpmxrZAJY1oOWEm07PRW/WgsNw4xsSfvFEHOZ4Fh+XKjNhLo5RL3oXnipNbv36Ex31umwUtcN50bqR003IWV3PeNrHgts1O7s1f7eJpaqel83kVEImpI14sT3m59lYJa4LaTplOhZeZvqXhbkZWqENG9xo4yJar2zJT5nW+LFrIYXX7YFQrT2PFeoDdRkBxFfDVfuGMPh88s98wZGnWIGNBPbpJR257v1aYlH+lRCiGuEEP9bCHEMwH8H8FisqxoQYW1X1YnjF+NWE8y8Frxlia/NNfzfbnkEr/9b/7jpX912CHccmnG+130s8byW6v8oUtut/+LLt+DnX7AfB7aORPo95c4LE74kUTdMu5uX/w1MbfC6+byq2Yty8wa1K62t4rX7QbNO3Jud3j7JrqHHGxMPQrnTe2WFA1ZjGXU++OEdgBJEzg7Rqf4TgSKupTBv/+2L2TR2TxVxy1tfgB+9dmfbc5XHLKi8bC1csX0MhilxOCSs1A3dJrYB1rWwIS1xIcSlQojfF0I8BuCvAZwAIKSUL5ZS/nXfVthHnMQ2n6OiLmi/i3C5Zvi6qVRi21pivKfmKrj3+DzOLrY2wtANE39x2yF89v5TzmNOs5e01xIfTHb6ltEcfu81B7u66PKZ5s0n6SjBmg8osVEbwvkuLPGqbpUCtc6d9pn+Zb/3hZXhOpZBTUpUEuTyELjTUymBdEr0NBFKbVDnK/5/j6heBxWaUpudIHd6Tks5oRz1OZ6xa9z3M8Vpie+ZsprhnJzrTWinm5h4wba8K3XDyk7fgJb44wBeCuAHpZQvkFL+FdZpz3RFc4pZ+01Dnfx+VtVcue6bMKLaRa7FGlfv57a4AeD0fBW6KVsyk70ZrkDn6WtxsBY36GQx67gBk04nS7sp8tGFttowWyxENXfaS80YbhFv69jmUy6nG/7x836g9VjE1ejTuZXwDV2nDYs6Fkqgg5K1clra8Sx2GvqhNlDTMYj47kkl4pWevF69i7ar6u9XaRh2YtsGs8QB/BiAp2H1Tf9bIcRLAR8/8zrCafbi8zO14614BFFKiQdOzOPKHeNtv6NEbC1xSSXi3zh0vuVx1et4sdJ+09NcN4JcJu0kQ/UL70jUbpgoZjFfruPkXBkfvfNor5fWVzpa4krkA27sflQbraMpLUvcPybe7Wv3g6C2q83EtvZNaWYAWcXZdKqnltt40Z5fHmCJh3Vgc6PWNF9uIJ9pn/vtfR4QRcTjs8THixmM5jWcuLB2S1z10s9FtcSzTcPLb/zteiHwU0kpPyOlfC2AywHcDuDXAWwVQrxfCPEDfVpfXwlruxrU/eyp2TJmV+q+QwOcOPoaRFRtGu44PONkz1vva4n4kk8iUFt2+oDmia/OEs9grtzAv9xzEn/4uUcT3U/dcZcHWeKrcKdXGq2xPdUkxRuyqdsJZBeGLDQRNEKzaFtN7klfg0psA6wNaKfhJ90wUbAEMqh7WWR3uqYs8XroMA/3OdJp6Ieag74tpPf7Wtg1WeyJJa566XcbE680DNQaZk//nsNElOz0FSnlP0opXwNgF4D7Abwj7oUNgrC2q+5dnZt7npoDAF8R74UlXmkYyGdSmFmu4xuHZ5zdqJr/67bEG6ZEJi1adueDKDFzLKjUat3pdWcYRr9r3HuFmpsNIDA8sBp3es2TZTua12BKYMVTvqQ2CBeWh0vEg2LiqZSwa6Cbn6PusyntF5l0qqfZzBOOJe5/LgTVz3vJak13eqiIu16nU0fAmy7djE/+4nMjt1PtFmvm+tpFvFvPTDMEaq5rS7yr4apSygsA/sb+t+4Ia7salNh291NzGM1rOLClPQM7LKM9KtWGiVc9YzvuPjaHP/rcI5geyWGpqmPHuLVrdluqumG2TGACrBP5fI+HEHSi4ePWj8pEMYP5csNJ5Ov38JZe4f6bd3KhBrnb/VA9oBUjOXuSWVVvSa5Ux21Ys9N9B3d4hgzF3XY1jEw61dMYqpPY1mFD19Gdbq9pvtxAPkSc3eGKTpZ4KiVw4/6p0OeshV2TBdxpGyBCiLZzOCphM9T9KLjymGrruNlLrJ9KCPEKIcQTQojDQohA610IcYMQwhBC/Hic6+lEWNtVJybusXjufWoO1+6Z9O33rS7ItbjTq3UDE4Usfv81B/Hk+RXcdfQCHjuziDsOW4luS67aU6v8onUduR7UqnfLWmLik3ZM/Ixtife7xr1XtIh4p5h4N4ltutFyUx4NmGRWH9LEtrphBNZfq5aiikG60zNp0VNLPJ9JIaulQjd0KdF57Ko7sS2KOz2bTsU2yjUquyeLKNcNzJUb+PS9J3HVf/sSvnd2qevXcfruR2672rxn13RzQ7ddXRVCiDSA9wJ4JYCDAH5SCHEw4Hl/AuBLca0lKs3s9PafFVzxFUW1YeB755bwzN0Tvq+nLIi1ZKcrd/pLr9iCd918Jf7uTTc6LWCz6RQMUzqdoBo+s3a9N8Z+4Nx8V+FOnyhmYErgiN3wpd817r3CvXEKcpfXjO4t8Uq91YpRIr7oyVBfzQahH9QawR23ch53erNOvP/u9PFiFlOlaIM+oiCEwEQhg/mARMOodcxOYltHEbeeNwzzs3dNFgAAX3jwNN7x6YegmxLHVtHQqVvPTNEeSLVUa6DexfSzpBHnp7oRwGEp5REpZR3AJwDc7PO8XwbwKQDnYlxLJJxmLxFLzBYqDUgJbB3zv9gza7TEG4YJ3ZQo2CP0fua5+3DTpZudzmZX2HN9lUvdT8TzriEA/UI3JFICq5pGptyO6pgl1hJ3/c39YuJSyqY7PcA688PbeSpokpl67dkhi4nXjeB6Xe+QITXSdhAlZu/7qWvxzldd3tPXnChmQi3xKOKkhL6um6ECrY5xp8z0frDLLjP7g8896qynm2RORbeeGRVeUtfARiwxWys7YTWIUZy0H3MQQuwE8CMAPhDjOiKjEtv8tMdPxJUFpTJPvSgLYrUx8WpAf+QfumYHAOBZe6xkOpXcphuyzYU9EEvcNFftwpv0TFLys8Tf9flH8Qt/991VvX6/6GSJu70zXZWY6UZLL3q/0izTlE5IY9gs8boeZol73OldxkB7yc6JAqYjjtyMykQhG+h1iToq0y30Ye5hlYndKR7eD3ZNFZyv//J1zwLQXTKnotuYuBpIpUJK67XtaleJbV3iZ4Z5/crvAfDbUkojbLydEOLNAN4MAHv27OnV+gIX52+Jtye2qRNRZZ56abrTVyeiynXvHSDyg1dvx+aRHOqGiY9985hzA7ey0z3u9Eyq79asbkhkVplRPOFp/ejnRXjk9ALufWp+qFspqo2bEP7ucvfPw4akeKk1zICYeHunMyGsG5hKKBoGaiEWp7eSwhnoMwB3ehxMFDM4HlAvHd0Sj5awpizxYXCnj+UzuHH/FF52xRZ834FN0FKiqxCSot6lJa7KFmmJr56TAHa7vt8F4LTnOdcD+ITdk/3HAbxPCPHD3heSUn5QSnm9lPL6zZs3x7Rc2Dc7/5/lfWLiyiU0XggQ8TW601WmrvdiFULguRdPO+/ruNP19lm7eS2NhiFhmKuPy3eLbqzBEveIuJ8XYaGio26YePxM98kx/UL9zadL/h3o3D9frumRzxGVI6Hws8TVebN5JNcytjIKpinx8KmFtja/vaIeYnFmPT0Nur1pDzuq8sKPWsSYbTaqiNuCNQzudAD45C8+F29+4cVWbkAxs0p3unUPixrbTqUEStm00yuBMfHu+S6AA0KI/UKILIDXAbjF/QQp5X4p5T4p5T4A/wLgl6SU/xrjmkKR0r/RC2DdSLSUaLkhuuf1+tErSzzoYlXtEh13utleYpZzPAj9s8ZVvfpqmCx63ent61ZTvx48Ob+q9+gHavOxZTSPhUrdpxmLLbSjVqlg1Lh4tWG0NK0oZdNIiVZLvGZYx2ybXYYYNS5erut40Z/djtf81R347U89GOl3gl4naOCFZYkH9/seluz0OJiweyD4UWsEHxc3LZZ4hBKzYczIVl0Zu2U150Mxp7nc6cN3LHpBbFeHlFIH8DZYWeePAfiklPIRIcRbhBBviet914IpZWhfWfd8WqB54/W6gBVrTWxrTqzy/zN5rbC6T4lZM3u5f53P/OrVozKWz7TkJPjFxJWI339iYVXv0Q/U33zrWA4NQ7Y3Y3H9HAju5OXGGqnY2nZVCIGxQqbFJa9eW3XgihoXPz1fcdy9qtnOaviTf3scP/K+O30H/9R0I8Sd3l5ilraHkawHxgsZa4yoz8a0HnHEptslHCZKSsSHxRJ3M1EI9kiE0cyRiH4+jOQ0zC5bfTLWqyUeZ0wcUspbAdzqecw3iU1K+XNxriUKEsGWOADks60iPlduQLNdNn44Ih6TJe4tL9J9stPVUIMLK3VsHy+gH+iGjDykwEsqJTBesMrMFiqNtni+YUos2ZnYDwyxJa7+5soavrBcb2nGUlfWsiO0nW9qDUPClO0377F8pmUmuSPi6r0j1oqr82jTSLarOL0b05S49eGnsVTVUWkYKGZbbzFh7nRv/obusylNMk7XtnID28Zb/4a1hrGKxLbg56s8Gu/xHwYmilmcmu+ug9sDJ+Zx55NWb4xueumXcmk8ZXe3pCW+ATClDB3xYpVrtTbxmChmg4cQrLFOXG0Ygjoz5TNp5LSUcwP3y05XMeZ+Nv1omHJVNeKKyWIW+6atshSvJa68DpPFDJ48v+w7/GMYUEK6c8LaOJ1fbrVsm+52yxKPYi07iY7eMZ4FraVO3LuBiGqJK5f8rsniqkX8vhNzTodAP2ur0jBCZ2C7O7bVfTalSUZVsfiFTqLWMUdNbMsPtTs9g4Uu3ek3v/dOvPerTwLoruSwlG2O6l2vbVfX56daLdK/vExRyKRbOrYtVOqB8XBg7e70agdLHADGChnnBu5305se6b+IW4ltq7eg3vC8fXjj8/cDaI+JK3G5bu8kpAROXOjNiMNeo/7mqkb23GJr61tHxG1LvJM7/Y+/8Cje99XDANpvzOOFAEt8rLuYuHqNPVNWh63VVDV86ZGzztd+Ir5QaQReM37u9PUk4pMuS9xLmIfCjVvAwuvEhyuxzY0acrRaumnD6/Z+rVd3+vr8VKvEiomHuNMz6dbs9HLDmRPsR7eJbfc8NdciWuq9wnbTo3nNiXfrZvtNbyCWuCFXHRMHLBH/4WfttAditB47lcSnxHGl3j5LexhQ7vKddreqc57+9fUuLfEvP3YOn7r3JID2Td1YPtOS86CO2aaRHNIp0fG133f7YfzLPScdi2W3Xde7Gmv8q4+fc8I8fhbnfLkRWM3h17FtPbnTx0NEPKz0zk0qJRwhT2xMvJi1Z3xH3yQe3D7mfN3NQJySS8SH0SvRCyjiLswOlnjem9hWDrYqAFezlwiW+IWVOn7iA9/ELQ80q/CqASVmbtzxUN2QbSe45e4H5vppiZvtpW6rIae1d5tTwrJjwrIyl6tDKuIuazgl0DaERv18qpS16mY7CGa5rmNm2T/L1joHXO5018zuyWIWFzo0k/nHbx/HZ+8/5YQm9kxZG6QoyXZeLqzUcdlWu5Og5zOZpsRiNXjj29axbZ1Z4hPOEBQfd3pIExwvTkvVCCI+jMKl7pld9Udwbe6muph7XqIlvrEIKzED2kV8odLAeEC3NqC7xLb5ch2mbL3xKdd9V+50z4maTglMFrOY7as7XfZk6EI+k25z6SqLc4cda/a2Gx0WlBjlM2lsGsnh3FLV9+dZLRWp5KbsCuN4E5rGCppvdnpWS2GqlAndwEkpcX6phgsrdSxWG0inBLbZCZCrqeWtNAxst/82XovTGtZjnbN+KHe6ymqvG9GFLQmozYvfce2mcVE2kogPrzvdyQ3oanqfiR+7dhee+O+vCKwG8mMk1/z8bPayAeiU2FZoS2wLj4mrG1AUd7oSI7f7uNmxLfjPNJrXHAtqsdLwzZS3YlD9E/G6YfZkBnQ+k2obRdq0xIdbxN1zs7eM5dotcdcwh8liJrT1qpTSI+LtlnilYbj6zbtfOxsaSlmoWMMh5ssNLNnjTMNit2FIKVFpGNhml815xapTSaaylNSxWW+WeDGbRibt360sasc2INpwk2Hqne5F3TO7uSepeeDdCrE7O3+9tl1dn59qDYRZ4gVXTLyum1ipG6Ex8VRKQEuJSO50JUbu51YbBoQIdwMpd/q5xSpmluu4fNtY23OmS7m+DsLwK3VbDTktjarXEreFQWV9rwypiCshymkpbB7JBcbEs+lU6GAM9VrujnttIl7w9gtovvdUKet0rPJDbS4urNSxVNUxVtBcllJ354xlRQOTpSyy6VSbWKkNWKA73T7P1SZkLaWKw4jVrSyLBb/s9IiJbUDTEg9zle+dKuINz93rDEsaJiZWsUmsNcyWJkdRaU1sG74NTS+giLswQ9quAq3u9KZVESzigHXBRbLEq+2WeNUuxwnre717qoCZ5Tq+fsiqobxyR7uIT5b6a4nrZnup22rwlvQBlhBoKYFN9nCKpSGNiSsPQjadwpbRfLCIO+704Buad4a916Jott9t3QjmtDSmStlQd7paV6Vh4NxSFaO5jJOA1W1im1pnMZPGeDHT9vvqM44HZqfbIm4fu/VWYgYENzqJmtgGNMUozJ2upVP4w5uv6ltviG5Qnhi/zQxg5U54qerGqixpxsQ3GFFi4soSb7ZcDY/PZNKpSJa4yrKue9zpnRJTnnPRNADgo3ceBQBc4SPiU6VcorLTFXmtPSa+UGlgrJBBOiVQzKaH2hLXUgKplMCWsRxml2st1nTN604P2WR5u721W+Kq/a51TqpjlrUt8bly3ffGCLQm3B2/UMZYQcNoTkMqYHBLGE5zomwaE4VM2026syWebll/wzDX1G9gGPHrn27YU+cii/gQDTdZDZOOO72BlZqOX/3EfTjh6hR49R/+O7715KzzfMOUaBhyVZZ0yY6JZ9OpVY1GTgLr6wpZI53arrZa4uF90xVZLRUpsW3ZSU5zlZjVzY6jBJ+xcxzFbBqPnF7EnqkixvLt65kqWXWZQTfyXmO503uQne5jiS9WdcfyHMlpQxsTd8c4N4/mYEpgdqXW8nMAyKXTESzx1s/oFxMHmkl/blf9ZDHrdL/zw51wd2qugtF8xuma182cc6C1JHLcx+J0BgYFWeKZVnd6Y5250wFgvNDeP93tOYmCyrUZhjGjq6GQSTvhlkfPLOKz95/Gu7/8PQDAHYdnsFzTcWSm2XtfbepWY4krd/p6tcIBingLEv5jSBWFjDURTLcTgYDgWeIK71CHIJZr1onqTuSK4kLKpFO4ft8UAH9XOmBZ4oZd3tMPLHd6jJa4XYecFBFXteBuq7fVnW711Pa6zRUr9rmh6q/b6sSVO73S6s1RljiAwLi4e02mbL5Hp42FH+5qCj+LU3kKwurEgeY1sN4S2wC7W5lnQ+X+e0XBscQTKuLOJLNy3TlHPnv/aRyfLePbRywL3F06qjbyqymXU+507zjn9cT6ukLWiJSyQ524PRFMN52kn6AbksKvYYkfy7XWpCQAqNY7u9MB4DkXdRJxa439cqk3emSJW54Pb7OXhiNaI/khF/F00xIHWhu+tIh4SDtOoFleduWOMaSEf7MXoGlt+4l4UFz8/FKtJQ9EvdZ4oV1sOlF1udPHC+391+fLdRQy6UCL0+tOr+vrT8QnfTY3aupc5MQ21ewlm9xjozZ56hwxTIm//MohfOeoJeLuMJk6H1ZjTdMS32CYJkIT21QMqtowHJfY1EgnSzwdLSbuY4mH9Zl286JLtyAlgBv3T/v+fKpkiUi/RFw31tY7XeHX7GWx0uz4VcpqQx0Tb1riVmOa867Wq3XDcCZ0OTHCgDKzSsP6jG+56WJ8+OduaIuFeufK1w0TQlidraZK4R37zi3VsG+65Hw/5lji3U+acg/s8dsELFSCu7UBPtnpplxXdeKAf7cyJwmyi8S2lOiuh/iwocayqnPkJ67bhX+556TTRll5JoFeWeLJPVadWL+fbBVIyI6JbYDlNryw0kA2nQqcYKaIaokvuRq2KCqesZNBHNwxhrv/6/fjxv1Tvj+fitB69W++9iQeOd2b0Z66ubbe6YpcJt3edrXaaokPa3a6252uMulnPDFxdRMO6+QFNDd4OyYKePFlW9p+ns+kkEkLx12tXlsIgckOIn5+qYZLtow436tjO7GamHi9GROfKGawXNNbKjM6dThUN9q67nanr7eYuAp9uJrzuEoCo5DLpJDvULUy7EzYmzwl4r/76iuciYtCtFriziCo1WSn2/fP1ZSnJQWKuAszvNeLI+LVhoG5lTomS5mOF5I1malzj+AV3zpxM/LuM6wV4VSHISg13cD//LfHccv9p31/3i0NQ/bEDWqVmDWPnZSyxZobyWlD2zu95hLpfCaFbDqFhYqVXHj43HKLyDt1swHua6d0K2BDJ4Ro6Z9ec9UcOxu4gA3CuaUato/nnWO6ppi4Ozvdp0ytsyWu3Om2iOtmT3IrhokJV2a2QlnikUVcSyU2Hq6YVJZ4uY7RvIaJYhbv+uGr8KLLNmPfdAnLdbc7vbvEPze0xDcYUnZObAMscb1QrjvDRcLIRc1Odzq2ud1I0WLinQhr9wg0k5u6GUgQht6jjm05Ld0WXmgY0onbjuS04e2d7hotKYSwxoVWdHzl8XP4/nd/DUdmVhwRV+dRUJlZ2b6hhc2GHis0+6dbNcd2LXE2jUImjQs+zX5quoGFSgNbRnPOJnDUFRNfquotZXGdqHrc6UC3Iq7c6XZMvEebwWHCr5GOu3tfFH7q2Xvxu6++oveL6yPumLja2LzqGdvxsTfeiNG85muJr0aIi9l0x4ZZSWf9frJVIDs2e7EOV8W2xKM04vfOSA7Cr2NbpW6g0IMdZDGbhpYSIWVGSsRXNzLVS6NX2ekZawOkSuOUZahiyKWc5riah426brTclMfscaGn5iuQEnjy3LLLnR7ewWqlgyUOWLFsd4mZ+6Y1Xsj4ViaogSqbR3POMVUbpOaaorvU3dnpSqzdn6mTOz3rk52eXWfudD+vS7clZs/cPYEfvXZX7xfXRyaKWdR0E2cXa20bO2+uiyPiq7DEhRAoZbWhHATTKyjiLiQ6t10FrJPqQrnuxBvDyPmUSfmx4tM7vapHS2zrhBAiNNtYzbr2tjhdLb2qE1cXnjomTllfsen6rRvmquZex423F7Y6/srafnqx2jJpKp9JBWaQV+oGUp3a77r+vu6kOutnWsuUM8XssvV3ny65LXHL2t8+biXjnZ6vtv1eEBU1dS+b9u3K1Y07vdowsFzTA4elJBUnzOB2p7ua82wU1HE4fqHcLuI5rSWxTV3/q+19XsqlaYlvFKK0XQVclngEd3rkZi8BlnivdpBhIn7ebvjRC3e6aUqYEj3p2KYuPG+rWzU5TiWtDKM17p3ApY6/2oiYsvWmvXk0h5nlWtvrAFY3v2JWCw31TJWag07qutHy3t554wrHs1HKOC59JeJ7pqyM9eN2J60oVOq647qc8FjiNd1ApWGEdjh0u9OfeHoJhikDyyaTipPE6NrcuEfHbhTU+XF6odIm4iO5dEBi2+ruhZdtG8PFm0c6PzGhBAfZNiBR2q4CVoxyvtKIaIl3505Xu07TlKjp0RPbOqHcuX700p3eMK3X6E3vdH9LfLLUdKcDVmOIbmYM9wOvJT6Wz+DozEqLe9r9862jeZxd9BfxSt3oOI1q80hzUpqfF+DsUrtF7XRQK2Sd46cs391TVs/trkTc1evfm9im/g+zrN0d2x62KyWu3DEe+f2TQMkObc23WOLdxcTXA2ozI2V7rw0rTOZKbOsy8c/L37/pxlWuMhlsnLMmAp0scVXu9fRCDVICUx1argLROrZJKdvc6U0XUvyWuONO74ElHmUGelSc5jrKEvd0yVNW4zA2fKm7kssAtzu9+TdwW8tbx/K+QgtYzV46ifim0RzKdQMrNb1tmIY76c2N2lBMFDO4ZMsIpkpZV5Z6BlOl7KpEXP2+9R7W51VT9DaFbLbU8ag1TDxyehFjeQ27JodvgMdaUBsc93ngbpO7UXDnRng3dt5OjM22q+s3rr0WNs5ZE4EO48SdRhiHzi0BAKbs+t8wslrnASiVhgGVBFx3datSv98LQkVcudMj1LN3QtVtK4FdCypGqmL13slxyhIfxjIzdx04YCeXuWLiQOvfdstYDucXazg+W8a17/oPHDq75PysbLvTw9isatGXa22JbWN5zfdv70wVK2Tw49ftwrd+5yUt2eC7p4rOYIooVOpNz1E6JVreV3kJVPc6P7R0ClpKoKYbeOTUAq7cMZ7oWuggrL7yPu70DSRS7soeb+vqUk5DTTeh22HItTR72QhQxF10avYyms9g50QB37Yn7ESJiUdJbFNlUiP2yQs0WzH2SsT9ejYrlDs9Sj17J1TstRcJScoSV+60+XIDebvRBdBsqTiMZWZ1w2wpiRkraDAlcHKu4jzmFtoto3ks1XTc+eQMLqzUcf+JeednUS1xwBLL9sS2DJaq7QNw5ssNjOY0ZOzGMN7s3z1Txa4s8aqnOZFVa1531gWEizhgHZOVmo7Hnl7CVTvXVzxcMT2Sw6wridFJbNuglrifOx1wdbFcQ9vVjQCPiotObVcB4LJtozi9YFmuKjYbRk5LwZRwdpV+KNfRVCmLumFCSumactU7S3yx4j/J7FwP68SV27anlrjjTq+37NodER9Cd3rNxxIHWhvutMTExyxxu+voBQDAqfmm2JfrnTv3KUv8/FKtzQswls/AlO0ei/lyPXCiGADsmSrg1HylpetaGN42we6NozrHNnXwXuUyaTx6ZhF13cRVO9dXPFyxaSTbch44zUzWcUMSL6oiA2gX8RF7fKhq+FJtmEinxLrrGdAreFRcdLLEAeDybaPO11GSqZza1xBXtVvEpbQ6nsXhTjclWjohAdbgAVVq1IvEtiVlifuMRO0W98AZoL3OeGTIY+LeWm2FKr9zx8y3jlklXd+xpzidmnOLuI5SJ3f6aKs73VtiBlhjXN3MV8LrtvdMFWGYEmcilplZfQ1a8wDmXe70UjbtWFlB5LQUHjplJbVdsX19WuJTpaxzzQGuxLYNJlJqQx5kiSsPW7VhIE8rPBAeGRdRmlNd7rqxRO3YBkQXccByxXbbxakTyr294GkoMrtcs0vCRE/qxOOIiddciW1u0Wm63YZLxKWUvi5txUWbrHKX1sQ2S4SVl8driXdyp0+VskgJSyzbEtvUvHGfqWJho3S7LTOrNAzks55kPvt8O79c6+hKB9TQG6vPwP5NpY7PTyLTpRzmyg3HO7cRE9uApks9UMRdyb4bKV+gWzbWWdOBTiVmAHCFbYkXs+lIiRbK2lIX6kfuOIovP3q25Tlqx+mIuG72/ML2a4MJNN2cuyYLvXGnx2mJV1pFR1mnXgtz0OimhJRoc2krLtlqi3hLYlu+5TW6daenUwJTpRzOL9daeqcD7nnjHhHvZIlPFwEAR2dXQt9bUW20dhicKLot8WokEVfH5KJNI+vWfbppRLXZdTXnSaeQ6kGr4iShzj3vOTji2ZzTEg+HR8ZFp7arALB/UwnZdCqSFQ6094N+3+1P4hPfPdHyHBWrVFN8aroRizsdaBdxlXC0e6qIasOKx68FZYmP9MEST6fsTnRdtAbtB35/O7e1cekWayPoFtrRnOa4ovOZFM7MV538hXJd7+iGBiyXuhUTN3zj8W3u9A5tULeP5bF1LIdvfO98x/cG2mPiqiJCSonzS1Etcev3L3WFrdYbajTw7IpKKDU3VI24Qt1DvUmwanPuiHgP+2WsRzbemRNCp7argFUGo2pqo+BuYKEbJmZXas7FqwizxHtljQSJ+NOLlvt2z1TRWedaWKo2UMike7Jud+KalNIWndbjPl3KYqZPc9Kj4iviLrG81McSF0I4LvUb90+jbpg4v1yDYUpUG2akuvtNI1mcX67bmfHN5/u5001TdnSnp1ICr7xqO772vfORQhYVj8dgopCFYUos13ScX6o5c9XDUBubS13jUdcb07Ylrmrn64axITOvJ4oZCGFtYN14E1ZrDWNDbnKiwiPjwpQSUTxa73zVFfjNl18W6TWVRVTXTcyu1CEl2tprKgtp2s7crekmaj2OiQeJ+Jn5ClIC2Gu7TqN0lwtjsaI7iVRrZbyQQUpYGd2VhoG6YbZZjtMjrUlCw4BfB66RrOZ4eQ5sHYEQaHMRKpf68y+eBmC51NV4z1Kus4hvHs3h1FylvU7c/nu4//bLdR2mbHdlennlVdtQ00189YlzHd/f2yZYbVzOLtawWNWjWeL2pnc9W+LKna7KzDaqJf78SzbhVc/Y3hZGUOc6LfFobLwzJwRTonONGYAXHNiEmy7dHOk1c07rUMPpjDbrGQu5UGkgp6WcZjJuS7xXO/QgET+9YMUqlbt2rcltS7WG061rraRSApPFLGZX6q5ubR4RL+XajmcQdd3Ee778Pdz60JmerC+Is7Z3w215plLCsYi3jOXxl697Fv7TDbtbfm/rWB5CAM9VIj5XccaQFjpkpwNWmdmMnaj4gks2OY8ry8bdP33BGSYT7lG6ft8UNo3k8G8PPd3x/dtKzOy/1eFzy876OuG407euXxGfVu50e/PpTYLcKLzm6h147+uvbXu82cTJuhdZI5k33vGJCnunu5ARLfFucGenz61YN85y3WjpwjW3Ys0mdwt+r2Piahzpv953Ch/6xhHc9hsvwnghg6cXqtg+XkDeU5O9Wpaqek8y0xVTpSwuLNedTmdt7vSRLO461lnEG4aJn/7wd3DX0Qu4YvsYXvWM7T1boxeVza1CFIrxQgbLNR2jOQ0/+Mwdbb/34ss2IyWAi+xhDafmK04b22IES0RZus+9aBrPvmjaeVxLpzCSa51k5hzPDk150imBF122GV95/JydM+J/gTQME7op22LiAHDY7nAYNTs9p6Xajt16YryQQTolmu50j+dko5PTrM593z4yiyPnV1CpG0M3G2GY4JnjolPb1dXgrhNXmeBAqzWusoSd3tG66TTY6FV2uurZ/PjTS5hZruOJp60b6+mFCraP5x131VprxRcrjZ5kpivUdK4FzxhSxfRIDnPlOowO9YEPnVrAXUcv4KJNJTzx9GJPy9IahomP3HHUsXSViHv7fo8VNEwUMoFC+KPX7sJfvO5ZGMlpGC9kcHKu7IReojQWUsL3ay870PYz97xxoH2saxjX7pnEhZV6aKmZcvt7O7YBwCFliUcQ8Wfvn8KPPGsn0us4U9vtYQLQVhK40RFCoJTT8I1DM/jUvSfxvbNLtMRD4JFxEaXZS7c4lnjDdHqUA61x8YWyNWdZxQNbSsx6eHG7s0CPzixDStm0xD3DRlZLLJZ4ue6UKnlFZ9OI1SBnrkOGump3+tobdsOUcBqK9IIvPHgGf/T5R/Glhy2X84kLZWwaybZllI8XMpFEEwAu3lzCobPLeOJpSwCjuJdfdsVWfO23XtRihSu8U+yCjqcf1+yeAICWVrBeqnU/Ebde+9DZ6CL+c8/fj//1Y1d3fF7S2eTK5bAsccZ83Yy4rp0aj08oFHEXUdqudosS8boRbInPlS13utsS73WzF8ASkXwmhWw6hSMzK1is6CjXDY8lvjYRX6zqPYuJA01LXN3wvP3qm/HFTiJuWZGvvtpyo993fL5na/yHbz8FoFnbffxCGbt93MGvv3Ev3vSC/ZFe8+COMTx6ZhGPP72IUjaNnROdp3mlUgJ7p/0bpIwVMp6YeOts9jAu3TqCYjYdeswcS9zHnf7E2SWM5jSnhJLYXdtW6vjqE+fw1IWVDdfopRMjOc3pbAiAlngIPDIuJIJjfqvFXet8brHmJK+5LXHlTncEPyZL/PU37sHvvvog9k4XceT8Ck4vWKKzfSLf1lhltSxWGz3LTgesErK5suXKzWqptt7bKlbWKUP9xIUKpkpZ7JosYv+mEu47PteT9T3+9CLufsp6LdUq9cRc2Tem++qrt+Onnr030uteuWMcS1UdX3n8HC7dNrrm83Isn/HExKNb4lo6hat3jYceMz8Rz2fSyGkpGKbEj123CxqFymF6JIcHTszjjR/9Lk7PV3Hd3slBL2moeP4lm/Cm5+93QlLMTg+GiW0uzBhi4u7EtvNLVVyxfQzfOXrBiYdJKbFg1z87gq+bsfRT/onrrWzob3zvPI7MrOBpu8Xn9vGCs861WOIqIa/XMXEpgQdPLmDXZKGtHEWV63SqFT85V3ZuCM/aPYFvHJ4JTdSKykfuOIqclsKuyeawkNPzVdz8zLUlZh202/uenKu0ZJqvlrGChsefblrip+etTU3Uev5n7ZnEh75xxM4Ubr+hqolTeU9nuYliBmcXa/iZ50bbvGwUpktZ6KbEM3eN4//94nMpUh5+/wcPAgC+d3YJJ+cqTPwLgUfGhZWd3lsZz7qs67OLNeyeKmIkpzmWeLnerH/O+lniMVgv+zeX8NTsiuNi7pU7vZd90xVqZvtDpxawe7JdGFVtfSdL/NRcxfn9q3aO4/xSDTMRS9OCOD5bxqfvPYXXP3sPDu4Yx6n5Cs7MV2GYcs3Z1ZdtG3UqJXpRbrV9PI+nF6pOtvuhc8s40EVDlWfsHEfDkE65mOKtH78Xf/+tY/jX+05BS4m219w1WcSLLtuMizev3+Ytq2H3VBHZdAp/8uNXU8BDuMQ+n3iMgqGIu5ASSPX4iCjrutIwMLNcw9axHKZHso6AqASjyRZ3uiXsmbSIpZ/yRZtKaBgSdz81h5QAtozmepLYphKneiniKo5arhu+wjhhN4QJi4mbpsTJ+Ypjie/fbMWNn4rYEzyI9371MFIpgbfcdDF2ThRwZr6KY/Zr+sXEuyGfSTvCd3kPGp9cv3cKuilx3/E5SClx6OwSDmyNLqxqGMkx1zGbXa7hCw+ewR/c8gj+6a7jeO0Nu7HLs9H60M9ej7/2qQXe6PzMc/bi6//lxbh82/qc1NYrDtgtiiniwVDEXZhSQvTYoa6s67OLVeimxJbRPDaN5BzLcW6lmWDkLkfzzoTuJaoO+Y5DM9gymoeWTvWkxExZ4r12pyv8RDxlD/7wtrJ1c94ez6lEfJ+d/HV0ZvUiXtdNfO7B0/jRZ+3E1rE8dk4WUDdM3GPHx9XwkLVwcId1g+9F97Lr9k1CCOA7Ry/g/JLVQU3dIKOgOvo9NdssM3v49CIAKwlJSwv8ykvbS9smS9mWTGNikdVS2DbeuQ3tRkcNC6I7PRheXS4iNmzrinRKQEsJnLBrbLeM5jBdyjo3wwWXJe51p8dVO6qsqtmVOt78wosAoCfudJX93OvsdMXuKf8MbatcJ9gSV2GDXfYmYNdkAemUaBGkbrn/xDzKdQMvumyL9Zp29vhn7z+FyWIG28bWfoP+sWt3IeeTzLcaxvIZHNw+hu8eu4Ab908BQFfu9GJWw9axXMvG52G7TO8Lv/J9qOmGMxOdkF5x2dZR7JsurusOfmuFIu7ClOh5djpg7SJVnfKWsRw2jeYci23e1f5SSwmkhMsSj0nEN43k8Bevuwa7JotOVmzeSWxbuyXeS3e6e1pckItalesEoY79btsSz6StRLRja3Cn33l4BilhdUcDgJ32ax+bLePHr9vVk2YlL7x0M14Ysb1vFG7cP4V/uus4HrUt6Eu6cKcDwN7pUksI4uFTC9g7XVxz6ICQIEo5Dbf/1osHvYyhhj4KNzG0XQUs19mJOWWJ57HJbmBimNLVTtTq5JXVUqgbZuz9lG++ZmdLWYuWtlodrqV3uoqJe0cLroWslnI2BUFisWkkh9PzlcAxqsri3jnR/P1906U1ifg3n5zBVTvHnSEf7jruHzi4ddWvGyfP3j+FasPEx+86jvFCJlIvczf7p0s4OtP0Xjx0agFX7Rjv9TIJIV1AEXcRR4kZYCW3KQt382jOKZtaqDQcd7pqjJHT0qg1jFhj4kHkM+k1udNVMxtV9tUrpktZTBQzgbH251w0jTMLVTx2Zsn357c9dhZX7Rxr6Sa2b7qIp2bKq5qfvlLTcd/xeTzv4mbpVymnYaJoNdP5vgO9s557yYsu24Krdo7h6MwKDmwZ6drrtHdTETPLNSzXdMyX6zg5V8FVOynihAwSiriLONquAs3xilbHtDQm7TjvhZUa5st1FDJpJyatLPGabvZslnhU8plU1+70mstyf3qxiqlStuctEjeN5EJLtl5+5VakUwJfeOh028+OzazggZML+CHPwJF9m0pYqumhbng3C5UGfuHv7sb//fZT+PS9J6Gbsm2S3TN2juNVV21v2SwME/lMGh/5uRuwd7qIG+y4eDfstxMCj82s4BuHZgAAV+1kdjUhg4QxcRdxtF0FmrXeW+ze0VOOiDcwV25g0tU1K5tOOW1X+52RqbwApikhROf8gA994wj+8rZD+M47X4ZCNo2zC9VYkpt+51WXI8xgnh7J4bkXTePWh57Gr73s0hZvyi0PWML+mqs9Im4L0pPnln0neaVEs7yvXNfxcx+9C/cdn8dXnziHYjaN5140jedc1CqEH/m5G1bx6frLltE8bnv7TauK2auWrvedmMdf3nYIl28bxbP3t/dpJ4T0D4q4C7MHHbz8UJb4ljGviNcwX25g3JW8lcvYIq4bfZ9sVMimcf+JeVz++19EXTedzPqJYgbv+6lrcd3epmgtVBr4y9sOYbGq46kLK7h82xjOLlWxdWztmdRe3O8bxKuesR3v/MxDOPC7/9b2sxv2TWKHp/e4ytB/7Qe/7ft6ozkN//H2m7BtPI+P3nkM9x2fx5/++NX4i9sO4dR8Bb/3moNt50q/PSerZbXtT/dOFyEE8Hv/+jC0lMDH3ngDp28RMmAo4h7iSGxT7uUto5aV6rbE58v1Nku8rptoGLLvTf/zmRQePmVlLv/ySy6BKSV0U+LzD5zBb3zyAfzbr74QS7UGXvUXd6CYTWPRzkZ/araMy7eN4emF2sASnX702p1Yqem+Mf0fuHJb22N7p4v4Xz/6DJxfaq8vX67p+JuvH8HXv3ceP/jMHfjIHUdx06Wb8RPX78az90/jyMyyU8O9kSjlNLzntdfg+GwZ1+2bxJVMaiNk4FDEXcTR7AVod6ersqm5ch3nlmrOqEfAKkdTJWZjPSzVikLe3mwc2DKC3/iBy5zHbzqwGa//0Hfw/tsP46LNI5hZrmH7eB6vvno7vvDgGTw1u4KGYWJ2pTawWuF8Jo3/bNe8R0EIgdfduMf3Z1JKfPq+U7jzyRms1K24+dtecgkAq4lLLxq5JJWbr9k56CUQQlxQxF3E0XYVcLvTLYHLZ9IoZdM4v1TDmYWKMx4TsKz2uj1IpN+uSpVcd/2+1olKz7tkE266dDNueeA0nn/JJozmNNzx2y9BOiVwx6F/x1OzZZxfqkFKrIuGH0IIPO/iadx5eBZ3Hb2AG/dN4YZ93SeCEUJI3DCg5aJfljhgtaM8dG4JDUO2xGvz2TQq9lCUbI+zvDuh3PfX+8SgX3rFFhybLePWh87g2r2TTmLUvukijl8o4+lFayLatvHex8QHwfMunsbMcg1nFqr4pRdfPOjlEEKILxRxF3G0XQWAXEbFxJsCN13KOvHnnRNN63W8kMFCpTGQOnG1Tj+r88V2e9G5cgM3uCz1PXbTlHO2iK8HSxyAUwN+1c6xtlIyQggZFijiLmSMbVeBpjsdsCxx1ehl+3jTEh8vaFioNFAbgDt980gOu6cKvj3Kd08VnV7b17tEfu9UEafmKk5r0/Ui4runiviVlx7Au26+KpZzghBCegFj4i5kjG1XgVZLfMpVVuZ2p08ULHEv5bS+14n/1ssvw1tffEmgaL3iqm04c+exlkS8vdNFmBK456k5ZNKi5XMlnbd//6WDXgIhhIRCEXcRV9vVTaUsNo/mUHKNZFRlZiM5rSULfbyQgSmtYSL9tsRLOa1ljV5++SUH8Ppn72mZ7asagNx19AK2jOZjmX9OCCHEH4q4C1PG03b1F2+6GK/1lDOp1qs7JvItlu94obVmfJjIaqkW1z8AXLy5hHRKYHal7oy4JIQQ0h8o4i7iion7WbhTjoi3iuK4u/FLArphTY/kcNvbb8ITZ5dwGWf+EkJIX6GIu5BSxpKd7kegiBeSJeKANUxkn93GlBBCSP9Ihkr0CYl42q76oUR8Z5iID5k7nRBCyHBBlXARV7MXP3ZMFCAEcPHmkZbHk2iJE0IIGQx0p7uIq+2qHzsnCrjt7Tc5IzEVE0Va4oQQQqJBlXBhSiCeIjN/Lto80laSVcikkUlbj9ESJ4QQEgZVooV4mr10gxDCcalTxAkhhIRBlXBhynh6p3fLmBJxutMJIYSEQJVwEVezl26ZoCVOCCEkAlQJF1JiKESc7nRCCCFRoEq4MKUc9BIAUMQJIYREgyrhZtgsccbECSGEhECVcGH2se1qGOP2OM9+jyIlhBCSLKgSLvrZdjUMutMJIYREgSrhwrLEB6/iz9ozgcu3jWLzaG7QSyGEEDLEsO2qCzkkdeLX7pnEF3/thYNeBiGEkCGHlrgLKdG3ASiEEELIWqGIu7CavQx6FYQQQkg0KOIurMQ2qjghhJBkQBF3MSwlZoQQQkgUKOIurMQ2qjghhJBkQBG3kXbLVUo4IYSQpBCriAshXiGEeEIIcVgI8Q6fn/+UEOJB+983hRDPjHM9Yai26YyJE0IISQqxibgQIg3gvQBeCeAggJ8UQhz0PO0ogJuklFcDeBeAD8a1nk6o4SfUcEIIIUkhTkv8RgCHpZRHpJR1AJ8AcLP7CVLKb0op5+xvvw1gV4zrCUXNL2OJGSGEkKQQp4jvBHDC9f1J+7Egfh7Av8W4nlCaljhVnBBCSDKIs+2qnxr6DuwWQrwYloi/IODnbwbwZgDYs2dPr9bXujCp3iuWlyeEEEJ6TpyW+EkAu13f7wJw2vskIcTVAD4E4GYp5azfC0kpPyilvF5Kef3mzZtjWSwT2wghhCSNOEX8uwAOCCH2CyGyAF4H4Bb3E4QQewB8GsDPSCm/F+NaOmKyxIwQQkjCiM2dLqXUhRBvA/AlAGkAH5FSPiKEeIv98w8A+H0A0wDeZ8eidSnl9XGtKXS99v+0xAkhhCSFWEeRSilvBXCr57EPuL7+BQC/EOcaosISM0IIIUmDHdtsmoltVHFCCCHJgCJuw7arhBBCkgZF3KaZnT7YdRBCCCFRoYjbsNkLIYSQpEERtzFpiRNCCEkYFHEbCVrihBBCkgVF3IZtVwkhhCQNirgN264SQghJGhRxG7ZdJYQQkjQo4jZsu0oIISRpUMRtTJWeTg0nhBCSECjiHmiJE0IISQoUcRvGxAkhhCQNiriN0+yFR4QQQkhCoGTZqAEodKcTQghJChRxG2WJE0IIIUmBIu5AS5wQQkiyoIjbmGy7SgghJGFQxG3YdpUQQkjSoIjbsMSMEEJI0qCI2zSnmFHGCSGEJAOKuI1jiVPDCSGEJASKuA1j4oQQQpIGRdxGOiVmA14IIYQQEhGKuA1LzAghhCQNiriNdGLiVHFCCCHJgCJuw3HihBBCkgZF3IFtVwkhhCQLirgNY+KEEEKSBkXchiVmhBBCkgZF3IZtVwkhhCQNiriNyex0QgghCYMirnDc6YNdBiGEEBIViriNyQEohBBCEgZF3IZtVwkhhCQNirgNS8wIIYQkDYq4DduuEkIISRoUcRvJtquEEEISBkXcRrLtKiGEkIRBEbcxTet/ajghhJCkQBG3Uc1eaIkTQghJChRxGzskTkucEEJIYqCI2zjZ6UxtI4QQkhAo4jbOFDMeEUIIIQmBkmXjNHuhJU4IISQhUMRt2HaVEEJI0qCI27DtKiGEkKRBEbdh21VCCCFJgyJuw7arhBBCkgZF3IbNXgghhCQNiriNU2JGESeEEJIQKOI2phMTH/BCCCGEkIhQxG3YdpUQQkjSoIjbMDudEEJI0qCI2zRj4oNdByGEEBIVirgN264SQghJGhRxm2aJ2YAXQgghhESEIm6jEttoiBNCCEkKFHEbyWYvhBBCEgZF3IbNXgghhCQNiriN0+xlwOsghBBCokIRt6ElTgghJGlQxG1MjjEjhBCSMCjiHlhiRgghJClQxG1Mtl0lhBCSMCjiNibbrhJCCEkYFHEbybarhBBCEgZF3IbzxAkhhCQNirgHlpgRQghJChRxG9OkJU4IISRZUMRt1AAUWuKEEEKSAkXchm1XCSGEJA2KuI2TnU4VJ4QQkhAo4jaSzV4IIYQkDIq4jSnZ6IUQQkiyoIjbSEha4YQQQhIFRdyGljghhJCkQRG3kZLxcEIIIckiVhEXQrxCCPGEEOKwEOIdPj8XQoi/tH/+oBDi2jjXE4aUkuVlhBBCEkVsIi6ESAN4L4BXAjgI4CeFEAc9T3slgAP2vzcDeH9c6+mEBBu9EEIISRZxWuI3AjgspTwipawD+ASAmz3PuRnA30uLbwOYEEJsj3FNgZimZI04IYSQRKHF+No7AZxwfX8SwLMjPGcngDMxrsvh20dm8fMf+y4AoKabKGTS/XhbQgghpCfEKeJ+dq1cxXMghHgzLHc7ACwLIZ5Y49rcbAIw47zXH/XwlZNJy/EgPB4ueCxa4fFohcejSRzHYq/fg3GK+EkAu13f7wJwehXPgZTygwA+2OsFAoAQ4m4p5fVxvHYS4fFohcejCY9FKzwerfB4NOnnsYgzJv5dAAeEEPuFEFkArwNwi+c5twD4WTtL/TkAFqSUfXGlE0IIIUknNktcSqkLId4G4EsA0gA+IqV8RAjxFvvnHwBwK4BXATgMoAzgjXGthxBCCFlvxOlOh5TyVlhC7X7sA66vJYC3xrmGCMTipk8wPB6t8Hg04bFohcejFR6PJn07FkJN7yKEEEJIsmDbVUIIISShbGgR79QWdiMghDgmhHhICHG/EOJu+7EpIcR/CCEO2f9PDnqdcSCE+IgQ4pwQ4mHXY4GfXQjxO/a58oQQ4uWDWXV8BByPPxBCnLLPj/uFEK9y/WzdHg8hxG4hxFeFEI8JIR4RQvyq/fiGPD9CjseGOz+EEHkhxF1CiAfsY/GH9uODOTeklBvyH6xkuycBXAQgC+ABAAcHva4BHIdjADZ5HvvfAN5hf/0OAH8y6HXG9NlfCOBaAA93+uywWgc/ACAHYL997qQH/Rn6cDz+AMBv+jx3XR8PANsBXGt/PQrge/Zn3pDnR8jx2HDnB6z+JiP21xkA3wHwnEGdGxvZEo/SFnajcjOAv7O//jsAPzy4pcSHlPLrAC54Hg767DcD+ISUsialPAqrouLGfqyzXwQcjyDW9fGQUp6RUt5rf70E4DFY3SQ35PkRcjyCWLfHQ1os299m7H8SAzo3NrKIB7V83WhIAP8uhLjH7owHAFulXa9v/79lYKvrP0GffSOfL2+zpwx+xOUi3DDHQwixD8CzYFlcG/788BwPYAOeH0KItBDifgDnAPyHlHJg58ZGFvFILV83AM+XUl4La6LcW4UQLxz0goaUjXq+vB/AxQCugTXT4M/txzfE8RBCjAD4FIBfk1Iuhj3V57GNcDw25PkhpTSklNfA6jJ6oxDiqpCnx3osNrKIR2r5ut6RUp62/z8H4DOw3Dxn1TQ5+/9zg1th3wn67BvyfJFSnrVvWCaAv0XTDbjuj4cQIgNLsP5RSvlp++ENe374HY+NfH4AgJRyHsDtAF6BAZ0bG1nEo7SFXdcIIUpCiFH1NYAfAPAwrOPwBvtpbwDw2cGscCAEffZbALxOCJETQuwHcADAXQNYX18RraOBfwTW+QGs8+MhhBAAPgzgMSnl/3H9aEOeH0HHYyOeH0KIzUKICfvrAoCXAXgcAzo3Yu3YNszIgLawA15Wv9kK4DPW9QkNwMellF8UQnwXwCeFED8P4DiAnxjgGmNDCPFPAF4EYJMQ4iSA/wbgf8Hns0urZfAnATwKQAfwVimlMZCFx0TA8XiREOIaWO6/YwB+EdgQx+P5AH4GwEN27BMA3omNe34EHY+f3IDnx3YAfyeESMMyhD8ppfy8EOJbGMC5wY5thBBCSELZyO50QgghJNFQxAkhhJCEQhEnhBBCEgpFnBBCCEkoFHFCCCEkoWzYEjNCNhJCCAPAQ66HflhKeWxAyyGE9AiWmBGyARBCLEspRwJ+JmDdC8w+L4sQskboTidkAyKE2GfPhn4fgHsB7BZCvF8Icbd7RrL93GNCiP8hhPiW/fNrhRBfEkI8KYR4i+t5vyWE+K49DEPNWC4JIb5gz15+WAjx2v5/WkLWL3SnE7IxKLg6bR0F8OsALgPwRinlLwGAEOJ3pZQX7E5UtwkhrpZSPmj/zgkp5XOFEO8G8DFYHbzyAB4B8AEhxA/Aaid5I6yBD7fYw3Q2AzgtpXy1/R7jffishGwYKOKEbAwq9tQlAM44yaeklN92Pec/2eNoNVitJQ8CUCKu5go8BGDEnim9JISo2n2kf8D+d5/9vBFYov4NAH8mhPgTAJ+XUn4jhs9GyIaFIk7IxmVFfWEPZvhNADdIKeeEEB+DZWkravb/putr9b0Gy/r+n1LKv/G+iRDiOgCvAvA/hRD/LqX8o55+CkI2MIyJE0IAYAyWqC8IIbbCmi/fDV8C8CZ73jSEEDuFEFuEEDsAlKWU/wDgzwBc28tFE7LRoSVOCIGU8gEhxH2wYtxHANzZ5e//uxDiCgDfsqfiLQP4aQCXAPhTIYQJoAHg/+vpwgnZ4LDEjBBCCEkodKcTQgghCYUiTgghhCQUijghhBCSUCjihBBCSEKhiBNCCCEJhSJOCCGEJBSKOCGEEJJQKOKEEEJIQvn/AUiREf9758m5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(lenn, prediction)\n",
    "# plt.title('Unemployment Rate Vs Year')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig('Anomaly_scores.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
